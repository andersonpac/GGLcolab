{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_RNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andersonpac/GGLcolab/blob/main/05_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiobin3g2wyW"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a specific type of architecture that is widely used to deal with sequential information. So far, the introduced CNN architectures from the previous tutorials treated inputs as independent objects, however, many applications need to deal with data that is interconnected. For instance, if you are translating a sentence from English to Taiwanese, and you are predicting the next word, it is useful to know which words came before the last one.\n",
        "\n",
        "RNNs are called recurrent since they apply the same operation to each of the input sequences, with the output of an individual element being dependent on the previous one. Theoretically, RNNs establish a connection between the actual input and ALL the previous ones. Although this is assumed, in the practice, RNNs have proven to only *remember* a limited number of inputs. In other words, RNNs have a *memory* that allows them to *remember* previous elements and use their information to deal with the current input. \n",
        "\n",
        "RNNs can be split into multiple types depending on their applications. For instance, if we want to predict one word given only the previous one, the topology of our network is a *One to One*. Another example is image captioning, where we can design a *One to Many* architecture to obtain a description from a single input image. The following diagram shows the different types of problems we can face ([Source](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)):\n",
        "\n",
        "\n",
        "![alt text](http://karpathy.github.io/assets/rnn/diags.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t6BQY9B21nV"
      },
      "source": [
        "**A Closer Look to RNN**\n",
        "\n",
        "The figure below shows the simplest version of an RNN, which can be easily derived from a simple feedforward architecture by adding a single loop: \n",
        "\n",
        "![alt text](https://i.ibb.co/qnGH6RT/vanilla-rnn.png)\n",
        "\n",
        "During training, the hidden state $h$ is iteratively updated based on the input value $x$ and the learned weights $W_h$ and $W_x$. The final output $y$ is estimated from the current state $h_t$ and the matrix $W_y$. \n",
        "\n",
        "Although RNN can assure short-term dependencies within the network, simple RNNs become unable to learn to connect information as the gap between past and present information grows. To overcome this limitation, in practical applications LSTM unit is adopted, that is a special RNNs architecture composed of multiple interacting layers ([Source](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)):\n",
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOUUKOPH2_SG"
      },
      "source": [
        "In this tutorial, we will use LSTMs straight away as a black box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ28M_227fj"
      },
      "source": [
        "# ***Many to One* RNNs - Regression**\n",
        "\n",
        "In this section, we are going to implement an easy example of an RNN in Keras. Given the records of a local newspaper, which indicates the number of new subscriptions per month, we want to predict the number of members that will join next month.\n",
        "\n",
        "First, we load the data with the utility method in Pandas `read_csv`, which allows us to load directly the dataset from an URL address. Let's print some rows of the imported record to see the format of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PZRejNk29jN",
        "outputId": "abb40677-c75e-4897-feae-0c32622d165a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# install ktrain first due to some dependencies needed for the transformer sec.\n",
        "!pip install ktrain\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import io\n",
        "import requests\n",
        "data=pd.read_csv(\"https://drive.google.com/uc?id=1Hv2nuwVXO_aZN89llGva0hSH6k3kKAVm\",usecols=[1],engine = \"python\")\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.33.2.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from ktrain) (1.2.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from ktrain) (3.5.3)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from ktrain) (1.3.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.8/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ktrain) (2.25.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ktrain) (23.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.8/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp38-cp38-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.0/266.0 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.8/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting transformers>=4.17.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.8/dist-packages (from syntok>1.3.3->ktrain) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.17.0->ktrain) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.17.0->ktrain) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect->ktrain) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ktrain) (1.26.14)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.33.2-py3-none-any.whl size=25313840 sha256=188784e66d1a1c556042ddb213e89bed6d762fc1f78ec5c37f465a337007692c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/a5/4d/055b452e87e0297d1f9656daa307b560113f2f1076613a9f86\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33516 sha256=aa69b30ffc65b2b9adfb8bff3730702264c6ed8cc58876bfb85585d1045155ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/34/ed/6bbd71716d7bcea30d75e8bc5aeb94f4cb52636295c8343534\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12304 sha256=7db9ffe8cb6ce52f0c62f67a448b3fbd7d98f25318f2355493f0702f11211361\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/cd/a7/a8fa93f7e177eee0101fed63179f7a2fa3b53671ffaad82bfd\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=689aa040e032d65dcc064b17abe6f3eadae9540885b60ce96526b45cd3182acd\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/bd/9a/ec6e575aaa50687d7af968bde7ce710b542eeaa9ee7978d4ba\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=07a853e1cc8db7f0f6581aefc4b3a10151399c853db9650a3fd24a14b8604cef\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/2b/f4/28f4bab995fa99c26b761bc7f9aeb5bf6c81e9be6ccd0b853b\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=b2c2d5dd0f19f3916944aace703de50b2dea91de2d5b69fab7738a3f48113fba\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/eb/bc/ce4bb467f5a7db6727f148f70bb0e52a62ef7edd41a19c8bdd\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6961 sha256=94a14fe82a1ef773c9ed5d6344194d4799afc0db4b11a435dabffc532f01a140\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/c4/ff/7e13e4f102c3b7d73ff075a50fe3266f3ec2de898d5493a8a2\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=3a1a923ef8c3ef4148e71d1d079b8cca046a78a8249a1814ab2177782b4fa484\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/15/39/59861ed531ef6c7c75810500eb22c68a425f82dde31d68630a\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18913 sha256=e32e6561decdb2a83430249c6f2998a8edf5c142f7feefe5d34913b4d938c6cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/13/2d/3de7c76f618a8d162884ac5b726a8c2242ad88afa370f1e62f\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=0140047d50ec0d1cc7ccb081a01eca15e887413cea4ee589c12ea66e5bb4da77\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect\n",
            "Installing collected packages: whoosh, tokenizers, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, keras-multi-head, huggingface-hub, transformers, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.12.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.33.2 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tokenizers-0.13.2 transformers-4.26.1 whoosh-2.7.4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Number of subscriptions to city newspaper\n",
              "0                                        112\n",
              "1                                        118\n",
              "2                                        132\n",
              "3                                        129\n",
              "4                                        121"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85fe1830-7833-49bb-bf86-1690affec97c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of subscriptions to city newspaper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85fe1830-7833-49bb-bf86-1690affec97c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85fe1830-7833-49bb-bf86-1690affec97c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85fe1830-7833-49bb-bf86-1690affec97c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd3kk4Zh3CA-"
      },
      "source": [
        "Moreover, let's plot the number of subscriptions per month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEmJqK1z3Dei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "83485caf-5351-451d-e450-f7870ee1b1ce"
      },
      "source": [
        "plt.figure(figsize = (15, 5))\n",
        "plt.plot(data, label = \"City Newspaper Subscriptions\")\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"1000 Subscriptions\")\n",
        "plt.title(\"Monthly Total Subscriptions to City Newspaper 1949 - 1960\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z8TX3X53FQT"
      },
      "source": [
        "Now we are ready to start importing Keras' modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zIY8Fz_3Gar"
      },
      "source": [
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x55PWxD3IFE"
      },
      "source": [
        "First of all, we need to prepare the data for the training and test stage. Once the data is loaded, we normalize the input values and split them between training (70%) and testing (30%).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIrOh9Pi3JZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba36a64-441d-417d-894e-82e23b81952e"
      },
      "source": [
        "# convert pandas data frame in numpy array of float.\n",
        "data_np = data.values.astype(\"float32\")\n",
        "\n",
        "# normalize data with min max normalization\n",
        "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
        "dataset = normalizer.fit_transform(data_np)\n",
        "\n",
        "# Using 70% of data for training, 30% for test.\n",
        "TRAINING_PERC = 0.70\n",
        "\n",
        "train_size = int(len(dataset) * TRAINING_PERC)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
        "print(\"Number of samples training set: \" + str((len(train))))\n",
        "print(\"Number of samples test set: \" + str((len(test))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples training set: 100\n",
            "Number of samples test set: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI5UamBO3KrU"
      },
      "source": [
        "We also arrange the dataset (input and labels) in the appropriate Keras' format by using the helper function `create_dataset()`. \n",
        "\n",
        "`create_dataset()` takes as argument the variable `window_size`. This variable is highly important when dealing with sequences since it is going to determine the length of our input data to the network. For instance, by setting `window_size` to 5, we will be using the last 5 monthly subscriptions values to predict the next one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvGh-1db3MOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6d03eb-dfca-4d43-e7b4-a8394d71dc29"
      },
      "source": [
        "# helper function to read data.\n",
        "def create_dataset(dataset, window_size = 1):\n",
        "    data_x, data_y = [], []\n",
        "    for i in range(len(dataset) - window_size - 1):\n",
        "        sample = dataset[i:(i + window_size), 0]\n",
        "        data_x.append(sample)\n",
        "        data_y.append(dataset[i + window_size, 0])\n",
        "    return(np.array(data_x), np.array(data_y))\n",
        "\n",
        "# Create test and training sets for regression with window size 5.\n",
        "window_size = 5\n",
        "train_X, train_Y = create_dataset(train, window_size)\n",
        "test_X, test_Y = create_dataset(test, window_size)\n",
        "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
        "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
        "\n",
        "print(\"Shape of training inputs: \" + str((train_X.shape)))\n",
        "print(\"Shape of training labels: \" + str((train_Y.shape)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training inputs: (94, 5, 1)\n",
            "Shape of training labels: (94,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlB3Edd03NwG"
      },
      "source": [
        "Once all the data is ready, we create the model as a `Sequential` object including 16 LSTM units and a dense layer outputting a single scalar.\n",
        "As mentioned, we specify a window size equal to 5, so that the prediction of the current element depends only on the previous five ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuT4lcHt3Qqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b07c645-6f32-4f03-be58-2cdb200fa0c8"
      },
      "source": [
        "batch_size = 32\n",
        "rnn = Sequential()    \n",
        "rnn.add(LSTM(16, input_shape = (window_size, 1)))\n",
        "rnn.add(Dense(1))\n",
        "rnn.compile(loss = \"mean_squared_error\",  optimizer = \"adam\", metrics = ['mse'])\n",
        "\n",
        "rnn.fit(train_X, train_Y, epochs=500, batch_size=batch_size, verbose=0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72c3ac5af0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMqbfrK3Nz8"
      },
      "source": [
        "Now we can compute the MSE on the training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkhF1mrr3Tor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13040786-76a5-4b50-b979-25c5adaa07d1"
      },
      "source": [
        "def get_predict_and_score(model, X, Y):\n",
        "    # transform the prediction to the original scale.\n",
        "    pred = normalizer.inverse_transform(model.predict(X))\n",
        "    # transform also the label to the original scale for interpretability.\n",
        "    orig_data = normalizer.inverse_transform([Y])\n",
        "    # calculate RMSE.\n",
        "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
        "    return score, pred\n",
        "\n",
        "mse_train, train_predict = get_predict_and_score(rnn, train_X, train_Y)\n",
        "mse_test, test_predict = get_predict_and_score(rnn, test_X, test_Y)\n",
        "\n",
        "print(\"Training data error: %.2f MSE\" % mse_train)\n",
        "print(\"Test data error: %.2f MSE\" % mse_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Training data error: 23.30 MSE\n",
            "Test data error: 54.40 MSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVOaCHMc3W6I"
      },
      "source": [
        "Moreover, we can plot the predictions and actual values in a graph to check visually the performance of our predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUjXRdOg3Vjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "df199896-2de0-4b6f-c284-e64702d33f49"
      },
      "source": [
        "# Training predictions.\n",
        "train_predictions = np.empty_like(dataset)\n",
        "train_predictions[:, :] = np.nan\n",
        "train_predictions[window_size:len(train_predict) + window_size, :] = train_predict\n",
        "\n",
        "# Test predictions.\n",
        "test_predictions = np.empty_like(dataset)\n",
        "test_predictions[:, :] = np.nan\n",
        "test_predictions[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n",
        "\n",
        "# Create the plot.\n",
        "plt.figure(figsize = (15, 5))\n",
        "plt.plot(normalizer.inverse_transform(dataset), label = \"True value\")\n",
        "plt.plot(train_predictions, label = \"Training predictions\")\n",
        "plt.plot(test_predictions, label = \"Test predictions\")\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"1000 member subscriptions\")\n",
        "plt.title(\"Comparison true vs. predicted in the training and testing set\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMzQDr20HPbw"
      },
      "source": [
        "#Sequence Modelling: Text\n",
        "\n",
        "Now we will use RNNs to tackle text examples. Text is one of the modalities that have been widely tackled with deep learning improving upon past methods. We will present two problems: classification and generation.\n",
        "\n",
        "A small summary of both problems is given below.\n",
        "\n",
        "**Classification**\n",
        "\n",
        "Classification is a standard problem, where we have some input data $x$ and try to classify it as one of the available classes $y$. In the case of sequential data, though, $x$ will be a sequence of elements that will be processed by the RNN to return the label $y$. The image depicts a sequence classification problem, where the red blocks are inputs, the green blocks the RNN model, and the blue block is the output. An example of a text classification problem that can be tackled with RNNs is \"Hate speech detection\", where the architecture must identify if an input text contains racist or sexist language, among others. \n",
        "\n",
        "![alt text](https://i.ibb.co/TtZPpZr/Capture.jpg)\n",
        "\n",
        "\n",
        "**Generation**\n",
        "\n",
        "In a generation problem, we aim to generate a sequence $y$ following the same distribution as the real data $x$. We will input the sequence into the model, and we will output another sequence $y$. Text translation is a typical example of many to many RNNs.\n",
        "\n",
        "![](https://i.ibb.co/7gSwnT2/Capture.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc5bCFhzQnQi"
      },
      "source": [
        "## Preliminary imports\n",
        "\n",
        "Here we include some of the used imports during the tutorial. Just run it to import the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2uDXpT1Qsqz"
      },
      "source": [
        "## These are just a bunch of imports\n",
        "## Just run them\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout, Flatten, Add, Lambda\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "from keras import __version__\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4kJNRmcq3DL"
      },
      "source": [
        "# Text Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLVCgocM6Kk"
      },
      "source": [
        "**References:** \n",
        "\n",
        "https://colab.research.google.com/github/csc-training/intro-to-dl/blob/master/day1/keras-imdb-rnn.ipynb#scrollTo=BYu8ql1nG7xc\n",
        "\n",
        "For the text classification example we will use the IMDB dataset available in Keras. The dataset includes tens of thousands of movie reviews taken from the IMDB website with a corresponding label for each review. The label is binary, and indicates if the review has a positive (label=1) or negative (label=0) sentiment. This problem is a quite standard Natural Language Processing (NLP) problem, and it is called sentiment classification or sentiment analysis.\n",
        "\n",
        "Before loading the data and building our model, we will explain a common part of NLP models, the embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAzSKba3J5NA"
      },
      "source": [
        "### Embeddings\n",
        "**References:** \n",
        "\n",
        "[1] https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "[2] https://colab.research.google.com/drive/1oXjNYSJ3VsRvAsXN4ClmtsVEgPW_CX_c?hl=en#scrollTo=p9q7qfXrvq-J\n",
        "\n",
        "\n",
        "Usually, the first step of text modelling is transforming the words into a numerical vector that represents the meaning or some properties of the word. This vector can be then processed by the network. To do so, we first will encode the word sequences in integer numbers, and we will also have a dictionary that contains the relationship `(actual word, integer)`. For example, the sentence \"the cat is on the table and the dog is on the mat\" can be encoded in the form $(7, 1, 3, 5, 7, 6, 0, 7, 2, 3, 5, 7, 4)$, with the corresponding dictionary $(and, 0), (cat, 1), (dog, 2)\\dots (the, 7)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhRu4KoqSVvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991db374-dcef-4e98-acbc-7a053d07b1a2"
      },
      "source": [
        "sentence = 'the cat is on the table and the dog is on the mat'\n",
        "## We form a list of unique words by using a set\n",
        "## which returns only unique elements\n",
        "## we also sort them, which is not necessary\n",
        "sentence_set = sorted(set(sentence.split(' ')))\n",
        "words = list(sentence_set)\n",
        "## We now form a dictionary in the form of \n",
        "## e.g. dict_words[and] = 1\n",
        "dict_words = dict((word, i) for i, word in enumerate(words))\n",
        "## We now encode the sentence in a list of integers\n",
        "encoded_sentence = [dict_words[w] for w in sentence.split()]\n",
        "print(sentence_set)\n",
        "print(encoded_sentence)\n",
        "print(dict_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'cat', 'dog', 'is', 'mat', 'on', 'table', 'the']\n",
            "[7, 1, 3, 5, 7, 6, 0, 7, 2, 3, 5, 7, 4]\n",
            "{'and': 0, 'cat': 1, 'dog': 2, 'is': 3, 'mat': 4, 'on': 5, 'table': 6, 'the': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoHyEZdVzHFD"
      },
      "source": [
        "Keras contains a class called `Tokenizer` that helps in performing this process. We will not use it for the examples in this tutorial, as we want to show all the steps involved in the tokenization process, but the `Tokenizer` class provides a high-level way to handle this preprocessing step. As it can be quite useful, we provide a small overview of it. [Here](https://keras.io/preprocessing/text/) you have a link to the Keras documentation explaining the different arguments of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5EL3-o5wsQl"
      },
      "source": [
        "import keras\n",
        "## First you define a tokenizer object\n",
        "## If you want a character level tokenization we set char_level=True\n",
        "## If set to false, it will tokenize in a word level\n",
        "## You can check in the documentation the different arguments\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=False)\n",
        "## Then you fit it on the data you have\n",
        "## The method expects a list of sentences\n",
        "tokenizer.fit_on_texts([sentence])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RBQrbI10CuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced67e60-e57c-4a0c-d17e-16dadb6f3e61"
      },
      "source": [
        "## Now, the class has formed a dictionary with all the words\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'is': 2, 'on': 3, 'cat': 4, 'table': 5, 'and': 6, 'dog': 7, 'mat': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKshU7Lj0Sgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08fa22f-57d8-4693-fbe6-71f34c478a9c"
      },
      "source": [
        "## You can also check the word count\n",
        "print(tokenizer.word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('the', 4), ('cat', 1), ('is', 2), ('on', 2), ('table', 1), ('and', 1), ('dog', 1), ('mat', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNI-js25161w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851d62aa-d5cf-438f-ced6-f6d4911b019e"
      },
      "source": [
        "## You can transform the data to sequences of integers\n",
        "## We print the first 10 elements\n",
        "tokenizer.texts_to_sequences([sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 4, 2, 3, 1, 5, 6, 1, 7, 2, 3, 1, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lITR0l3SUAU"
      },
      "source": [
        "Now that we have the sequence in the form of a list of integers,  we could input that directly to the RNN. However, as those numbers are arbitraryly chosen, it would be really hard for the RNN to understand the relationships between the words. To give the model more representation power, we first want to transform the integer to a vector of dimension $d$ which represents the semantic meaning of the words. Each of these vectors is called an Embedding. The actual values of the vectors are not important, only the relationships between them. For example, `dog` and `cat` vectors are probably going to be closer than `dog` and `the`. Or if you are doing sentiment classification, probably two words encoding similar positive sentiments will be closer than a word expressing positive sentiments and a completely neutral word.\n",
        "\n",
        " The embeddings can be initialized randomly and the model will learn suitable values to reduce the loss during the training process. However, embeddings which have already been trained in a large corpus of text such as Wikipedia can also be used. Examples of these pretrained embeddings are [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) or  [GloVe](https://nlp.stanford.edu/projects/glove/). These methods are trained using the context of the words, for example predicting the surrounding words when a specific word is given. As a result, words that appear in similar contexts have closer embeddings.\n",
        "\n",
        "![alt text](https://i.ibb.co/s5sg6dZ/Screenshot-from-2019-02-08-15-13-41.png) \n",
        "\n",
        "The image shows relationships between words in the embedding space.\n",
        "\n",
        "\n",
        "\n",
        "We now download the GloVe pretrained vectors trained in Wikipedia and Gigaword. [Here](https://nlp.stanford.edu/projects/glove/) you have an overview of what GloVe is. We will see how the embeddings contain a semantic meaning that allows us to model semantic relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie3ToDUgKWN4",
        "outputId": "4b905831-1223-4533-879c-ba9f7ee9d904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Download and unzip glove pretrained embeddings\n",
        "!wget https://imperialcollegelondon.box.com/shared/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt -O gensim_glove_vectors.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-04 19:50:30--  https://imperialcollegelondon.box.com/shared/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 74.112.186.144\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt [following]\n",
            "--2023-03-04 19:50:31--  https://imperialcollegelondon.box.com/public/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt [following]\n",
            "--2023-03-04 19:50:31--  https://imperialcollegelondon.app.box.com/public/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 74.112.186.144\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl2.boxcloud.com/d/1/b1!WoK0wss3ObU3JBagaBkOoYfIqdSjwQIfaF6TRuyd4HSt0Fc_XQGUt7AQsnWl5Z9LM83FLCw9wXepaiRFuHyePG6JyRCnujnay-smjoumRv2eixq6tUrRXu0CInE_MfZvu10o0zP93aD2eHYRgHJmr19xoHO3oBjre0UUSCfsulDJVn7lwWEi0Kl3f4zPi7V9I9yzYAb5VpIJhypeel-1Q6WFNy7Wi91qeFXPn5Cmbr4J3VrHSj4jTwRMNisGU3ZvtnB_OOC-V1OPrcpPIRaGDbfIzlPnePbP7bNPkoVZl_vN4jB3g64pCNZ-rRGepu1NCdEKzJ_zkBHkuRiYt296DWoB09VN1SlrGw32OwKjPy8VHyJAdZbjee85JmfWaigOxnT67Tw_IIgnuZyTDPbIVs5KtEMrubF1JCoECOV4UbWbkETvRBe-PYbFv6HkLjvMmX0nwmOACDbmXA4dPRi3wFkBfMblnT_Ve7dB_n5JoCN_23u32rP6N1BuMtwlbbE5735PmhDwlcxVx_8RluLKLxtQRVEhKJYIhxT7qO0Q0YLdajSVI_om2xyBtFNNUbKd0gkaoAN-BHrGZgbkWV7954SJEIoEBnK2FI5cCUIuAIu4jSpByfEOowxzZbrM2kWPSGNKlKJeYyXVI5PK0Vr76V6J4wJsBLDFazzbTjr-qWTq0iEXEL82tfwcWSgn7V3WUA6IiU95i_tfKM6hMhDwYPggsjbeU-MVnJw11Lmme1fgWgZVFQkm1sN6nBGl1ICpMIjTthAsmwrswDl5uJhs_7loq59Vlh1W-SAg_pd-sRCPd9EqmGjGrkyY7BIdYhc5IxUoobz9zFCOFUCiqPyaimkqV-MjIvN7YoU-hZWgpHenrWJt0SPY7bKkdGimljUP2OuhpP6UNrfINixe2oYUyLQURhaAS4ZewYwfkVmimJbpC8exGKahqkbCDmuPrhSXocLuBlY8gYv1jG6lZIS0qS_rAGiWZWWZBzyoZTozpuKNje7mr8COmTipsrUoDcQdQcg_n92yWan_1fp3DUKJG6ENxXSf6RYoh1gEof2cGN6hekXYZ2b1FE-VbEfJsIWAOk0t4cDowKawwr-2j3Jc6ci_I0QJg7cHKaneVP9ql0aI_Y2fZ3oX-97rDNcputayHLiyRc2Xp0NAcLkhTX9mT68euX3bEcbPAnleCNaeFYAWm_HYZCiVNAG0jbM-He0DeCWcmr0TBIDniyTXlqER1pfd9_Nme_jQpUI0jf30F27rRahoXm7fHsZ9R9JCHtxN69Y66ICw7P0C8CvQtxhI8on-SHUloLRYPngb4WCOJSmqcQ0IjNdlQuYsjYYQY45shbhgB190T7JOU_TUpeXJKmmcpyGh8MBb1oNmytBlndTC4wWdv4yqbSFlPY-hkyknLTsa7UcNcsWHgwAv1PTaWYb1ZughVrSuaVhMZaimwqUIEHuMY_ZQP793TERYwq7kqOt5IA../download [following]\n",
            "--2023-03-04 19:50:31--  https://dl2.boxcloud.com/d/1/b1!WoK0wss3ObU3JBagaBkOoYfIqdSjwQIfaF6TRuyd4HSt0Fc_XQGUt7AQsnWl5Z9LM83FLCw9wXepaiRFuHyePG6JyRCnujnay-smjoumRv2eixq6tUrRXu0CInE_MfZvu10o0zP93aD2eHYRgHJmr19xoHO3oBjre0UUSCfsulDJVn7lwWEi0Kl3f4zPi7V9I9yzYAb5VpIJhypeel-1Q6WFNy7Wi91qeFXPn5Cmbr4J3VrHSj4jTwRMNisGU3ZvtnB_OOC-V1OPrcpPIRaGDbfIzlPnePbP7bNPkoVZl_vN4jB3g64pCNZ-rRGepu1NCdEKzJ_zkBHkuRiYt296DWoB09VN1SlrGw32OwKjPy8VHyJAdZbjee85JmfWaigOxnT67Tw_IIgnuZyTDPbIVs5KtEMrubF1JCoECOV4UbWbkETvRBe-PYbFv6HkLjvMmX0nwmOACDbmXA4dPRi3wFkBfMblnT_Ve7dB_n5JoCN_23u32rP6N1BuMtwlbbE5735PmhDwlcxVx_8RluLKLxtQRVEhKJYIhxT7qO0Q0YLdajSVI_om2xyBtFNNUbKd0gkaoAN-BHrGZgbkWV7954SJEIoEBnK2FI5cCUIuAIu4jSpByfEOowxzZbrM2kWPSGNKlKJeYyXVI5PK0Vr76V6J4wJsBLDFazzbTjr-qWTq0iEXEL82tfwcWSgn7V3WUA6IiU95i_tfKM6hMhDwYPggsjbeU-MVnJw11Lmme1fgWgZVFQkm1sN6nBGl1ICpMIjTthAsmwrswDl5uJhs_7loq59Vlh1W-SAg_pd-sRCPd9EqmGjGrkyY7BIdYhc5IxUoobz9zFCOFUCiqPyaimkqV-MjIvN7YoU-hZWgpHenrWJt0SPY7bKkdGimljUP2OuhpP6UNrfINixe2oYUyLQURhaAS4ZewYwfkVmimJbpC8exGKahqkbCDmuPrhSXocLuBlY8gYv1jG6lZIS0qS_rAGiWZWWZBzyoZTozpuKNje7mr8COmTipsrUoDcQdQcg_n92yWan_1fp3DUKJG6ENxXSf6RYoh1gEof2cGN6hekXYZ2b1FE-VbEfJsIWAOk0t4cDowKawwr-2j3Jc6ci_I0QJg7cHKaneVP9ql0aI_Y2fZ3oX-97rDNcputayHLiyRc2Xp0NAcLkhTX9mT68euX3bEcbPAnleCNaeFYAWm_HYZCiVNAG0jbM-He0DeCWcmr0TBIDniyTXlqER1pfd9_Nme_jQpUI0jf30F27rRahoXm7fHsZ9R9JCHtxN69Y66ICw7P0C8CvQtxhI8on-SHUloLRYPngb4WCOJSmqcQ0IjNdlQuYsjYYQY45shbhgB190T7JOU_TUpeXJKmmcpyGh8MBb1oNmytBlndTC4wWdv4yqbSFlPY-hkyknLTsa7UcNcsWHgwAv1PTaWYb1ZughVrSuaVhMZaimwqUIEHuMY_ZQP793TERYwq7kqOt5IA../download\n",
            "Resolving dl2.boxcloud.com (dl2.boxcloud.com)... 74.112.186.128\n",
            "Connecting to dl2.boxcloud.com (dl2.boxcloud.com)|74.112.186.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1037962830 (990M) [text/plain]\n",
            "Saving to: ‘gensim_glove_vectors.txt’\n",
            "\n",
            "gensim_glove_vector 100%[===================>] 989.88M  27.2MB/s    in 65s     \n",
            "\n",
            "2023-03-04 19:51:38 (15.2 MB/s) - ‘gensim_glove_vectors.txt’ saved [1037962830/1037962830]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDs0EebuUJ5x"
      },
      "source": [
        "We will now load the GloVe embeddings. We use `gensim` to manipulate the embeddings, which is a nice tool that can be used to play with GloVe or Word2Vec embeddings. This piece of code takes some time to load, as the embeddings file is quite large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK0qwB--K0Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ac8605-b112-46bf-8b12-61842b15fcf4"
      },
      "source": [
        "## We load the embeddings\n",
        "## Gensim is a really useful module that provides high-level function\n",
        "## to use with the embeddings\n",
        "!pip install gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrj-dPMbSsrc"
      },
      "source": [
        "Now we will do some operations using the embeddings of the words. First, we will do some words arithmetics based on the embeddings, which it will show us that the words encode some semantic meaning. For example, the distance between words with similar semantic meaning but different genders is approximately fixed. Meaning that the vector resulting from doing $man - woman$ should be similar to $king - queen$, hence:\n",
        "\n",
        "$king - queen \\approx man - woman \\rightarrow woman + king - man \\approx queen$\n",
        "\n",
        "We can check this using the method `most_similar` and the `positive` and `negative` arguments as following:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PYEzmorMFD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec97994-63fa-4632-b6a2-989051c18ff1"
      },
      "source": [
        "## We can do word arithmetics. \n",
        "## We look for the nearest neighbour of the vector resulting on doing\n",
        "## the operation 'king' + 'woman' - 'man'\n",
        "glove_model.most_similar(positive=['woman', 'king'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6713277101516724),\n",
              " ('princess', 0.5432624220848083),\n",
              " ('throne', 0.5386104583740234),\n",
              " ('monarch', 0.5347574949264526),\n",
              " ('daughter', 0.498025119304657),\n",
              " ('mother', 0.4956442713737488),\n",
              " ('elizabeth', 0.4832652509212494),\n",
              " ('kingdom', 0.47747087478637695),\n",
              " ('prince', 0.4668239951133728),\n",
              " ('wife', 0.4647327661514282)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1bgFWT3aGUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145cad9e-a9fc-4127-ef3b-8ab4f8824654"
      },
      "source": [
        "## Similar examples\n",
        "glove_model.most_similar(positive=['google', 'ios'], negative=['apple'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('android', 0.5720318555831909),\n",
              " ('apps', 0.5662358999252319),\n",
              " ('app', 0.5322650671005249),\n",
              " ('facebook', 0.4770544171333313),\n",
              " ('smartphones', 0.47069066762924194),\n",
              " ('gmail', 0.4677259922027588),\n",
              " ('firefox', 0.4666402041912079),\n",
              " ('skype', 0.4491073191165924),\n",
              " ('iphone', 0.44582629203796387),\n",
              " ('web-based', 0.44464385509490967)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J09zgTciaHU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2238345-fdd6-47bb-8263-c65fd132ce23"
      },
      "source": [
        "glove_model.most_similar(positive=['england', 'paris'], negative=['france'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('london', 0.6710129976272583),\n",
              " ('manchester', 0.5267472863197327),\n",
              " ('birmingham', 0.49347949028015137),\n",
              " ('liverpool', 0.49033817648887634),\n",
              " ('oxford', 0.4811282157897949),\n",
              " ('middlesex', 0.47516536712646484),\n",
              " ('surrey', 0.46148526668548584),\n",
              " ('sussex', 0.45899876952171326),\n",
              " ('leeds', 0.4551934599876404),\n",
              " ('essex', 0.45398280024528503)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7LMqhpATsAL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "34e3e56d-4632-4706-ac9b-ff775a1cdba2"
      },
      "source": [
        "## We can also check the word that does not match the rest\n",
        "glove_model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cereal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g85rTdpOY-HZ"
      },
      "source": [
        "To check out other functions you can call use [this](https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjgjAlaBQvaH"
      },
      "source": [
        "In http://projector.tensorflow.org/ you can visualize the words projected in the $\\mathbb{R}^3$ space using either PCA or tSNE, which are both techniques for dimensionality reduction. There, you can see how words are clustered by meaning or topic.\n",
        "\n",
        "\n",
        "![](https://brenndoerfer.github.io/deep-sentiment-analysis-distill/img/tensorboard_projector.gif)\n",
        "\n",
        "Image taken from [here](https://brenndoerfer.github.io/deep-sentiment-analysis-distill/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30w3Y4oHJy79"
      },
      "source": [
        "### IMDB\n",
        "Now let's start tackling a text classification problem. We first load the IMDB dataset for sentiment classification. As we said, it contains movie reviews with a corresponding binary sentiment label (label=1 corresponds to positive sentiment, and label=0 to negative sentiment). The words are already encoded as integers in order from most common words to less common (e.g. `the` is a common word so it should be encoded as a small integer). That makes it easy to filter the non-common words by using the argument `num_words` when loading the data. The filtered words will be all encoded as a special token `<UNK>`, which means unknown. For example, if we want to load the dataset with only the top $5000$ most common words we can do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWU0zG7AHd3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325e16ca-2992-42e7-e24e-579416327c7a"
      },
      "source": [
        "# number of most-frequent words to use\n",
        "nb_words = 5000\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=nb_words)\n",
        "print('x_train:', x_train.shape)\n",
        "print('x_test:', x_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "x_train: (25000,)\n",
            "x_test: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiYpN-jwcGd-"
      },
      "source": [
        "We see that the dataset contains 25000 examples for both train and testing. Let's print an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF2twk31cNiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031ea0c8-6035-4b55-f3e6-c9ba3af15c4d"
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqxzLNgAcUmL"
      },
      "source": [
        "The printed example is a sequence of numbers. It is important to note that there are three special integers in this IMDB dataset: $0$, $1$ and $2$. $0$ will be used to pad the sequences, which we will explain now. $1$ is used as the `<START>` token (you can see how the printed sequence starts with a `1`). $2$ is the token `<UNK>` which is used for all the filtered non-common words. If we want to retrieve the actual sentence, we can use the dictionary given when using the method `get_word_index()`. However, the given dictionary when calling `get_word_index()` does not take into account the three mentioned tokens, so we need to modify it a little bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y26JIPAadBtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aeb728-55b1-4f98-c75c-5a30d89cf9b4"
      },
      "source": [
        "# get_word_index retrieves a mapping word -> index\n",
        "word_index = imdb.get_word_index()\n",
        "# We make space for the three special tokens\n",
        "word_index_c = dict((w, i+3) for (w, i) in word_index.items())\n",
        "word_index_c['<PAD>'] = 0\n",
        "word_index_c['<START>'] = 1\n",
        "word_index_c['<UNK>'] = 2\n",
        "# Instead of having dictionary word -> index we form\n",
        "# the dictionary index -> word\n",
        "index_word = dict((i, w) for (w, i) in word_index_c.items())\n",
        "# We now retrieve the sentence\n",
        "sentence = ''\n",
        "for index in x_train[0]:\n",
        "  sentence += index_word[index] + ' '\n",
        "print(sentence)\n",
        "print(y_train[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <UNK> with us all \n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyhd3lQefNH4"
      },
      "source": [
        "We can see how we just recovered the sentence that we had printed before as a sequence of numbers. We can also see how there is no punctuation in this dataset. The review is clearly positive, so the corresponding label is \"1\".\n",
        "\n",
        "One of the problems with the given text data is that the sequences all have a different length. We want to give Keras a batch of inputs with fixed dimensions. To do so, we define a maximum length `maxlen`, and truncate the sentences longer than that, and also pad with $0$'s at the beginning the sentences shorter than that length. We use the method `sequence.pad_sequence` from `keras.preprocessing`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGcgjhlVbyOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1a6440-a935-40ff-ace9-e9b7274020a4"
      },
      "source": [
        "# Truncate sentences after this number of words\n",
        "maxlen = 80\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXCucplf0M5O"
      },
      "source": [
        "We can check how some sentences are padded at the beginning to be of length `maxlen`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeBf1oOJzr4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ef699b-bf79-4da5-b001-f0a1f7f9ff34"
      },
      "source": [
        "x_train[5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    1,  778,  128,   74,   12,  630,  163,\n",
              "         15,    4, 1766,    2, 1051,    2,   32,   85,  156,   45,   40,\n",
              "        148,  139,  121,  664,  665,   10,   10, 1361,  173,    4,  749,\n",
              "          2,   16, 3804,    8,    4,  226,   65,   12,   43,  127,   24,\n",
              "          2,   10,   10], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ljchrWPMz3"
      },
      "source": [
        "We will now build the model we will use for sentiment classification. The model is formed by an Embedding layer, where the model will learn a vector of dimensionality `embedding_dim` for each of the words; an LSTM layer and a linear layer that maps the output of the LSTM to 1 value. We train this with the `binary_crossentropy` loss and `sigmoid` activation as we only have two classes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh2cHXD5HjQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf76361d-66a9-452b-f08e-271fe990433c"
      },
      "source": [
        "## Model parameters:\n",
        "# Dimensions of the embeddings\n",
        "embedding_dim = 300\n",
        "## LSTM dimensionality\n",
        "lstm_units = 128\n",
        "\n",
        "print('Build model...')\n",
        "text_class_model = Sequential()\n",
        "\n",
        "text_class_model.add(Embedding(nb_words,\n",
        "                    embedding_dim,\n",
        "                    input_length=maxlen))\n",
        "\n",
        "text_class_model.add(LSTM(lstm_units))\n",
        "\n",
        "# To stack multiple RNN layers, all RNN layers except the last one need\n",
        "# to have \"return_sequences=True\".  An example of using two RNN layers:\n",
        "# model.add(LSTM(lstm_units, return_sequences=True))\n",
        "# model.add(LSTM(lstm_units))\n",
        "\n",
        "\n",
        "# You can add some dropout if you want\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "text_class_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "text_class_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(text_class_model.summary())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 80, 300)           1500000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               219648    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,719,777\n",
            "Trainable params: 1,719,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTDlUcEF0mqn"
      },
      "source": [
        "Let's train it for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJfDwWRlHoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ed57a6-e97c-4241-8949-888cf44008a5"
      },
      "source": [
        "## We train the model for 5 epochs and check the accuracy in a validation split\n",
        "epochs = 5\n",
        "validation_split = 0.2\n",
        "\n",
        "history = text_class_model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=epochs, validation_split=validation_split)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 22s 126ms/step - loss: 0.4674 - accuracy: 0.7703 - val_loss: 0.3724 - val_accuracy: 0.8312\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.3144 - accuracy: 0.8674 - val_loss: 0.3719 - val_accuracy: 0.8324\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 5s 34ms/step - loss: 0.2580 - accuracy: 0.8935 - val_loss: 0.4062 - val_accuracy: 0.8272\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.2060 - accuracy: 0.9176 - val_loss: 0.4514 - val_accuracy: 0.8188\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 0.1749 - accuracy: 0.9326 - val_loss: 0.5146 - val_accuracy: 0.8190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tVyZLyv0rbO"
      },
      "source": [
        "This is a classification example, so let's print the loss and the classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3D78e9yHo8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "33e917e2-c7b8-41a1-e6b9-d3089c2d6b97"
      },
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'], label='training')\n",
        "plt.plot(history.epoch,history.history['val_loss'], label='validation')\n",
        "plt.title('loss')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'], label='training')\n",
        "plt.plot(history.epoch,history.history['val_accuracy'], label='validation')\n",
        "plt.title('accuracy')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAADSCAYAAAA/vMlrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqRElEQVR4nO3deXxU1fn48c+TnYQEAgFCNhIQCIQlgYRFFBE3FA3gAlasYkWq1S9V236/+Kt1abW1rV+/1lZFVGqroiAVcUFFatwqSwKEyBLZIQuQBAiBJGQ9vz/uJYQYQoCZzEzmeb9eeTkz9945z42Th3vmnHseMcaglFLezMfVASillKtpIlRKeT1NhEopr6eJUCnl9TQRKqW8niZCpZTX00So3I6I7BaRy10dh/IemgiVUl5PE6FSyutpIlRuS0QCReRZESm0f54VkUB7W4SIfCgipSJySES+FhEfe9v/iEiBiBwVke9F5DLXnolyd36uDkCpFvwaGAUkAwZYCjwM/Ab4BZAPdLP3HQUYEekP3AekGWMKRSQe8G3bsJWn0StC5c6mA781xhQZY4qBx4Ef29tqgJ5AL2NMjTHma2PdOF8HBAIDRcTfGLPbGLPDJdErj6GJULmzKGBPo+d77NcA/gxsB5aLyE4RmQNgjNkO3A88BhSJyNsiEoVSLdBEqNxZIdCr0fM4+zWMMUeNMb8wxvQG0oEHT3wXaIxZYIy5yD7WAH9s27CVp9FEqNzZW8DDItJNRCKAR4A3AETkWhG5QEQEOILVJa4Xkf4iMt4eVDkOVAL1LopfeQhNhMqdPQFkATnAd8A6+zWAvsAK4BiwEnjBGJOB9f3gU0AJsB/oDjzUtmErTyO6MKtSytvpFaFSyutpIlRKeT1NhEopr6eJUCnl9TQRKqW8ntvdaxwREWHi4+NdHYZSqp1Zu3ZtiTGmW3Pb3C4RxsfHk5WV5eowlFLtjIjsOd027RorpbyeJkKllNfTRKiU8nqaCJVSXk8ToVLKsxzcAct+BVuXO+wt3W7UWCmlfsAY2JkBq+bCtk/BNwA6xUC/Kx3y9poIlVLuq7oCchbC6pegeAuEdINL5kDqTyC0h8Oa0USolHI/Rwog82VY+xpUHobIITD5RRh0A/gFOry5ViVCEZkA/AWrGtgrxpinmmyfgVVDosB+6W/GmFfsbbdjVR4DeMIY8w8HxK2Uam+MgfxMWPUibF4KGEicCKN+BnGjQcRpTZ8xEYqIL/A8cAVW+cRMEXnfGLO5ya4LjTH3NTm2C/AokIpVO2Ktfexhh0SvlPJ8tdVW4lv9IhSshcBOMOoeGDELwnud+XgHaM0V4QhguzFmJ4CIvA1MApomwuZcBXxmjDlkH/sZMAGrFoVSypuVl8Dav8OaV+DYfuh6AVzzNAz9EQR2bNNQWpMIo4G8Rs/zgZHN7HeDiIwFtgIPGGPyTnNs9DnGqpRqD/ZvtK7+ct6BuirocxlM+pv1Xx/XzOhz1GDJB8BbxpgqEfkp8A9gfGsPFpFZwCyAuLg4B4WklHIb9XWw9VNY9QLs/hr8OkDKdBh5N3Tr7+roWpUIC4DYRs9jODkoAoAx5mCjp68Af2p07Lgmx37RtAFjzDxgHkBqaqpWk1KqvTheBuvfgDUvweHdEBYDlz8Ow26D4C6ujq5BaxJhJtBXRBKwEtvNwC2NdxCRnsaYffbTdGCL/fhT4PciEm4/vxItrahU+3dwB6yZB+vfhOqjEDsKLn8MEq8DX/ebtXfGiIwxtSJyH1ZS8wXmG2M2ichvgSxjzPvAbBFJB2qBQ8AM+9hDIvI7rGQK8NsTAydKqXbGGNj1pXX3x9ZPwMcPBl1vdX+jh7k6uha5XV3j1NRUowuzKuVBaiohZxGsngtFmyE4wrrzI+1OCI10dXQNRGStMSa1uW3ud42qlPIMZYWQ+Qpk/R0qD0GPwTDpeRh0I/gHuTq6s6KJUCl1dvKz7Ls/3rNGgxMnWhOge41x6t0fzqSJUCl1ZnU19t0fc63b4ALDYMRPYcRd0CXB1dGdN02ESqnTqzh08u6Po4XQpTdc/SdIvgUCQ10dncNoIlRK/dCBzdbVX85CqD0OvcfBdc/CBVe47O4PZ9JEqJSy1NfDtuXW3R+7vgS/IBh6szX9pfsAV0fnVJoIlfJ2VUetic9rXoJDOyE0Ci57FIbPcKu7P5zJ4xNhXb3hSGUNXUICXB2KUp7l0C777o83oKoMYkbA+IdhQDr4+rs6ujbl8YnwoXdzWLe3lIWzRtG1o+NXrlWqXTEGdn9jTX/5fhn4+ELSFBh5D8QMd3V0LuPxifD6YTEszS7ktvlrWHDXKDp18K5/yZRqlZrjsHGxlQAPbIQOXeDiX1h3f4RFuTo6l/P44Z9Rvbsy98fD2XrgKD95LZOK6lpXh6SU+yjbB58/Af+XBEvvta4I0/8KD26Gy36jSdDm8VeEAJf2785zN6dw74J13PXPLF69PY0gf19Xh6WU6xSstRY/2LQE6muh/9XW6G/CWI+9+8OZ2kUiBLh6cE/+fONQfvHOBu5bsI4Xbx2Ov6/HX/Aq1Xp1tbDlfWv+X95qCAiFtJkwcpY1EVqdVqsyhYhMEJHvRWS7iMxpYb8bRMSISKr9PF5EKkUk2/6Z66jAm3PD8Bh+NymJFVuKeGBhNnX17rWyjlJOUXEIvvk/+MtQWHwHHCuCCU9Z3d+rn9Ik2AoOq2InIqHAz4HVTd5ihzEm2THhntmPR8dTUV3HHz7OJSTAjz9cPxgfH+0KqHaoKNe6+tvwNtRWWt3eiU9D3yut0WDVao6sYvc74I/Arxwa4Tn46SV9KK+q5bnPt9MhwJdHrxuI6PciytMZY633l7sMcj+EfdngGwhDplqrv/RIcnWEHsshVexEZBgQa4z5SESaJsIEEVkPlAEPG2O+btqAM4o3PXBFP45V1TH/P7voGOjHL69yfYEYpc5afR3sXQW5H8H3H1l1PxCISYMrfgvJ0yEkwtVRerzzHiwRER/gGezl+ZvYB8QZYw6KyHDgPRFJMsaUNd7JGcWbRITfXDuAiupa/paxnZBAP+4Z18cRb62Uc1VXwM4MK/lt/QQqDlpXfr0vgYsegH5XQ2gPV0fZrjiiil0oMAj4wu5+RgLvi0i6MSYLqAIwxqwVkR1AP6BN1uIXEZ6cMpiK6jr++EkuIYG+3DY6vi2aVurslB+0kl7uR7Djc+s7v6BO0G8C9L8GLrisXS175W7Ou4qdMeYI0HBtLiJfAL80xmSJSDfgkDGmTkR6A32BnQ6M/4x8fYT/nTqUiuo6Hlm6ieAAP24cHtOWISjVvEO77C7vMti7Eky9Ve5y2G2QeI214rOX3fPrKo6qYnc6Y4HfikgNUA/c7Yoqdv6+PvztlhRm/iOL/168gQ7+vkwc0rOtw1DezhhrgCP3I2vAo2iT9XqPQTD2V9aS95FDdMKzC3hVFbuK6lpue3UN2XmlvHxbKpcmdndKO0o1qKuxFjk4ceVXVgDiA3EXWokv8RoIj3d1lF6hpSp2XpUIAcqO13DLy6vYduAYr90xgtF9ujqtLeWlqo7C9hX2YMdyqDoCfh2s7/kSJ0LfqyBEP3dtTRNhE4fKq5n20koKSit5Y+ZIhsWFO7U95QWO7ofvP7aS364voa4agrta9/j2n2gtdR8Q7OoovZomwmYUlR3nppdWcri8mrdmjSIpqpPT21TtTPFWa2Lz98usym4A4Ql2l3cixI7UOzzciCbC08g/XMFNc1dSXVvPwp+O5oLuHdukXeWh6uuhIMtKfrnL4OA26/WoFCvx9Z9o1fbQwQ63pImwBTuLjzH1pZX4+fjwzt2jie2i3RfVSM1x2PWVfeX3MZQXgY8fxF9sJ79roFO0q6NUraCJ8Ay27Cvj5nmr6NTBn0U/HU1kp6A2bV+5mcrDsO0zK/lt/zdUH7OWtOp7OSReCxdcDh06uzpKdZY0EbZCdl4p019eRWSnIBb9dLTWP/E2R/JPLmaw5z/WYqYdI63pLf0nQsLF4KefCU+mibCVVu08yO3z19CnW0femqX1T9o1Y+DAJmugI/dD2LfBej2i/8nBjqhh7bKYubfSRHgWvvi+iLv+mcXg6E68fudIQgLbzSLeqq4W8uyVXHI/gtI9gEDsiJODHREXuDpK5SSaCM/SJxv3ce+C9YxM6ML8GVr/xKNVV1iLGJxYyaXykL2Syzg7+V0NHfUOI2/QUiLUy51mTBjUkz/fWMeDizZw75vrmPtjrX/iUcpLGq3kkmGv5NIZ+l1lJb8+l0GgTpVSJ2kiPI3rh8VQXl3Hb97byAMLs/nLzSn46pL/7uvQTnuw4yOr+2vqoVOsvZLLROh1oa7kok5LE2ELfjyqFxVVtfzh41yCA3x56vohWv/EXdRWWyu5bFtuJb8iu3JEj8Ew9r+t0V5dyUW1UqsSoYhMAP6CtQzXK8aYp06z3w3AYiDNXpQVEXkIuBOoA2YbYz51ROBtpXH9k+AAP61/4irHy6zb2PauhD0rrTs8ao9bK7n0GmNVbet/ta7kos6JU6vYichArIVck4AoYIWI9DPG1DnuFJzvgSv6UV5dx6vfaP2TNnP0AOz91qrXsXcl7P/O6u6KL/QcAql3QtwoiL8Igru4Olrl4ZxdxW4S8LYxpgrYJSLb7fdbeb6BtyUR4eGJJ+ufBAf68rNxOs3CYYyBgztOJr4938LhXdY2/2CISbW6u3GjrKJFOtChHMzZVeyigVVNjv3BjZnOqGLnaCLCE5Ot+id/+uR7QgL8uP3CeFeH5ZnqamF/jnWlt3ellfzKi61twV0hbjSkzbT+23OIDnIop3N2FbtWcUYVO2fw9RGevsmqf/Lo+5sIDvDlptTYMx/o7arLIT/rZOLLy4SacmtbeLx1727caOsnoq8OcKg259Qqdq041uP4+/rw1x+lcNc/s/iff+UQHOCn9U+aKi85+d3e3pXW7Wv1tYBY9TlSplvd3LjREBbl6miVcnoVu0pggYg8gzVY0hdY47jwXSPI35eXfjyc2+ev4edvr6dDgA/jE720zqwxVtHxvatOfsdXstXa5htofb835udWjY7YNKtEpVJuxqlV7Oz9FmENrNQC93raiPHpBAf48eqMNKa/vJq731jHa3ekcWGfiDMf6Onq66zFChonvqP7rG1BnayrvORbrMQXlawrtiiPoPcan6d2X/+k5jgUrG30/d4aqCqztoXFQK/Rdjf3QuiWqKu1KLeliy44Wbuqf1J5GPauPpn4CtdbhYgAug2wkl6vC60rv846UKQ8hybCNpB/uIKpc1dS5Wn1T0rzTh3YOHGrmo+/VYvjROKLHakTl5VH00TYRqz6J6vw8xH3rH9SXw/FuafO3ztiTxENCLXW5YsbbXV3o4Zp+UnVrmgibEO5+8uY9tIqwjr48c5PL3Rt/ZPaaqtr2zjxHS+1tnXscXLuXq/R0D0JfHUNDtV+aSJsYy6rf3K8zBrMOJH4CtZaCxMAdL3ATnoXWt3d8ASduKy8SvtemHXTEijMtv+opdEftzR5zX696WtCC9vO9r2s15OBD0dX8NrKPSx4YTl3Xtyb4AC/c3ivxtua7mO/V22VPar7rTWtpbmFCeJGQ8du5/VrVqo98/xEuONz2PC2NbEX++r2xOPGr7WxBOBxH6ACawamM+nCBEqdF89PhOl/tX5aw5jmk2TT1864jVMft7B/Ru5+fr1kIylxnfnfm4YQ5OfTwns1fq2VcYkvdO2jCxModR48PxGeDWncrWwbl6ZF8kvfCB5ctIHKDw4w99bhBPjppGOl3In+RbaB64fF8MTkQXyeW8QDi7Kpq3evASqlvJ13XRG60K2jelFRXcvvl+US7O/LH2/Q+idKuQtNhG1o1tg+HKuq47l/byMkUOufKOUuWtU1FpEJIvK9iGwXkTnNbL9bRL4TkWwR+cauVYKIxItIpf16tojMdfQJeJoHLu/LnRcl8Nq3u3l6+feuDkcpheOKNy0wxsy190/HWrF6gr1thzEm2aFRe7CT9U/qeD5jB8EBftx7qdY/UcqVHFK8yRhT1mj/EFw1ec9DWPVPBlFRXcufP/2ekABfZoxJcHVYSnkthxRvAhCRe4EHgQBgfKNNCSKyHigDHjbGfH3u4bYfjeufPPbBZoID/Ziq9U+UcgmHTZ8xxjxvjOkD/A/wsP3yPiDOGJOClSQXiEhY02NFZJaIZIlIVnFxsaNCcnv+vj787ZYULu4bwZx/5fBRzj5Xh6SUV2pNIjzbAkxvA5MBjDFVxpiD9uO1wA6gX9MDjDHzjDGpxpjUbt28657YQD+r/snwXuH8/O31fJ57wNUhKeV1WpMIG4o3iUgAVvGmU+qUiEjfRk8nAtvs17vZgy2ISG+s4k07HRF4e3Ki/smAnmHc/cY6vt1e4uqQlPIqZ0yExpha4ETxpi3AohPFm+wRYoD7RGSTiGRjdYFvt18fC+TYry8G7jbGHHLwObQLYUH+/PMnI4jvGszMf2axds9hV4eklNfQ9QjdTFHZcaa+tJKD5dW87en1T5RyIy2tR6j3GruZ7mFBvDFzJKGBftz26hq2Fx11dUhKtXuaCN1QTHgwb8wciYgw/ZXV7D1Y4eqQlGrXNBG6qd7dOvLGzBFU1dYz/dVV7D9y3NUhKdVuaSJ0Y4mRYfzjjhEcLq9h+iurKDlW5eqQlGqXNBG6uaGxnXn19lQKSiu57dU1HKmocXVISrU7mgg9wMjeXXnpx6lsKzrKjNfWcKyq1tUhKdWuaCL0EJf068ZffzSMnPwj3PWPLI7X1Lk6JKXaDU2EHmTCoEievmkIq3Yd5GdvrqO6tt7VISnVLmgi9DBTUhrVP1mo9U+UcgRdqt8DTR/Zi4qqOp5ctoUOAb78fspgrYyn1HnQROih7hrbm2NVtfzl39vIyC3ihuExTE2N5YLuWthdqbOl9xp7MGMMX24t5q01e/n3liJq6w2pvcKZmhbLtUN6Ehyg/84pdUJL9xprImwnio9W8e66fBZm5rGzpJyOgX5cN7Qn09LiGBrTSavlKa933olQRCYAfwF8gVeMMU812X43cC9QBxwDZp0o7iQiDwF32ttmG2M+baktTYTnxxhD1p7DvL0mj4++K+R4TT39e4QyLS2WKSnRhIcEuDpEpVzivBKhvbDqVhpVsQN+1LiKnYiEnSjgZK9R+DNjzAS7rOdbWAWgooAVQD9jzGknwWkidJyy4zV8sKGQRZl5bMg/QoCvD1ck9eDmtFjG9InQAvPKq7SUCJ1dxW4S8LYxpgrYJSLb7fdbedZnoc5aWJA/00f2YvrIXmzZV8bCzDyWrC/go5x9RHfuwNTUWG5KjSGqcwdXh6qUSzm7il00sKrJsdHnFKk6LwN6hvFYehJzrk5k+eYDLMrM4/9WbOXZf29lbN9uTEuL5fIBPXQajvJKDhtWNMY8DzwvIrdgVbG7/QyHNBCRWcAsgLi4OEeFpJoR5O9L+tAo0odGkXeogney8liUlc/P3lxH15AApqREMy0tlr49Ql0dqlJtpjXfEY4GHjPGXGU/fwjAGPOH0+zvAxw2xnRquq+IfGq/12m7xvodYdurqzd8ta2YhWvyWLHlALX1hmFxnbk5LY6JQ3oSEqjTcJTnO9/BEj+swZLLsMp4ZgK3GGM2NdqnrzHmROW664BHjTGpIpIELODkYMm/gb46WOK+So6dnIazo7ickABfrhsaxdS0WFJiO+s0HOWxzmuwxBhTKyInqtj5AvNPVLEDsowx72NVsbscqAEOY3eL7f0WYQ2s1AL3tpQEletFdAxk1tg+3HVxb9bttabhLM0u5O3MPPr16MjU1FiuHxZDF52Go9oRnVCtzujo8Ro+zNnH25l5bMgrxd9XuHJgJNPSYrnoAp2GozyD3lmiHCZ3/8lpOKUVNUR37sBNqTHclBpLtE7DUW5ME6FyuKraOj7bfICFmXl8s70EgIsuiODmtDguH9idQD9fF0eo1Kk0ESqnyjtUwTtr81mclUfhkeOEB/tz/bAYpqXF0k+n4Sg3oYlQtYm6esPX24pZlJXHZ5sPUFNnSInrzLTUWK4dGkVHnYajXEgToWpzB49VsWR9AQsz89hWdIzgAF+uHWKthjMsTqfhqLaniVC5jDGGdXtLWZSZxwc5hVRU13FB947cbK+G07VjoKtDVF5CE6FyC8eqavlwQyELs/JYv9eahnPFwB5MTY3l4r7d8NVpOMqJNBEqt7P1wFEWZubx7rp8DlfUENUpiBtTY7lpeAyxXYJdHZ5qhzQRKrdVVVvHis1FLMzK4+ttxYA1DWdqaixXJvXQaTjKYTQRKo+Qf7iCxWvzeScrn4LSSsKD/Zlsr4aTGBnm6vCUh9NEqDxKXb3hP9tLWJiZx/LN+6mpMwyN7czNabFcp9Nw1DnSRKg81qHyansazl62HjhGB/8T03BiGd4rXKfhqFbTRKg8njGG7LxSFmbm8cGGQsqr6+jTLYSbUmNJHxql5QbUGbVFFbsHgZlYS20VAz8xxuyxt9UB39m77jXGpLfUliZCdSblVbV8lLOPhVl5rN1zGBEYmdCFycnRXD24J506+Ls6ROWG2qKK3aXAamNMhYjcA4wzxkyztx0zxnRsbbCaCNXZ2F1SztLsQpZmF7CzpJwAXx/GJ3Zncko0lyZ201Fn1aAtqthlNNp/FXDruYerVOvFR4Tw88v7MvuyC8jJP8J72QV8sKGQTzbtJyzIj4lDejIpOZoR8V103UR1Wg6rYtfIncDHjZ4HiUgWVrf5KWPMe2cbpFJnIiIMje3M0NjO/PqaAfxnx0HeW1/A0uxC3lqTR1SnINKTo5mSEk3/SF0RR53KofMQRORWIBW4pNHLvYwxBSLSG/hcRL4zxuxocpxWsVMO4+frwyX9unFJv25UVNfy2eYDvLe+gJe/3sncL3eQGBnKlJRo0pOj6NlJB1mUA6vY2TVL/gpcYowpOs17vQZ8aIxZfLr29DtC5Swlx6r4KGcfS9YXkJ1XigiMSujK5JQoJgzSQZb2ri2q2KUAi4EJJ6rZ2a+HAxXGmCoRiQBWApMaD7Q01VwirKmpIT8/n+PHj7d8pqrVgoKCiImJwd/fO//4d5WUszTb6jrvKiknwM+Hy+xBlnH9dZClPXLE9JlrgGc5WcXuycZV7ERkBTAY2GcfstcYky4iFwIvAfWAD/CsMebVltpqLhHu2rWL0NBQunbtqhNoHcAYw8GDBzl69CgJCQmuDseljDFsyD/Ce+utQZaD5dV06uDPNYN7Mjk5ijQdZGk3PH5C9ZYtW0hMTNQk6EDGGHJzcxkwYICrQ3EbtXX1fLO9hPfWF/DppgNU1tQR3bkD6clRTEmJ1rIDHu58p8+4BU2CjqW/zx/y8/VhXP/ujOvfnfIqe5Alu4B5X+3kxS92MKBnGFNSokgfGk1kpyBXh6scyMfVAXiK0tJSXnjhhbM+7pprrqG0tLTFfR555BFWrFhxjpEpZwgJ9GNySjSv3TGCVQ9dxqPXDSTAz4ffL8tl9FP/5paXV7EoM4+y4zWuDlU5gMd0jV3dhdu9ezfXXnstGzduPOX12tpa/Pw85sL6FO7we/U0u0rK7fmJBew+WEGAnw+XD+jO5ORoxvXvToCfXlu4q5a6xvp/rZXmzJnDjh07SE5OJi0tjYsvvpj09HQGDhwIwOTJkxk+fDhJSUnMmzev4bj4+HhKSkrYvXs3AwYM4K677iIpKYkrr7ySyspKAGbMmMHixYsb9n/00UcZNmwYgwcPJjc3F4Di4mKuuOIKkpKSmDlzJr169aKkpKSNfwsqISKEB67oR8Yvx7HkZxdyy4g4Vu88xKzX15L25Ar+35LvWLPrEPX17nWBoVrmcZcyj3+wic2FZQ59z4FRYTx6XVKL+zz11FNs3LiR7OxsvvjiCyZOnMjGjRsbRl3nz59Ply5dqKysJC0tjRtuuIGuXbue8h7btm3jrbfe4uWXX2bq1Kn861//4tZbf3g3YkREBOvWreOFF17g6aef5pVXXuHxxx9n/PjxPPTQQ3zyySe8+mqLg+/KyUSElLhwUuLC+fXEAQ2DLEvWFbBg9V6iO3dgkj3I0lcHWdyexyVCdzFixIhTpp4899xzLFmyBIC8vDy2bdv2g0SYkJBAcnIyAMOHD2f37t3Nvvf111/fsM+7774LwDfffNPw/hMmTCA8PNyRp6POg7+vD5f2786l9iDL8s37WbK+kLlf7uCFL3YwsGdYw50sPcJ0kMUdeVwiPNOVW1sJCQlpePzFF1+wYsUKVq5cSXBwMOPGjWt28ndg4MnSlb6+vg1d49Pt5+vrS21trYMjV84UEujHlJQYpqTEUHy0ig9zCnlvfQFPLtvC7z/ewoV9ujIpOZqrB0USGuSdk9ndkX5H2EqhoaEcPXq02W1HjhwhPDyc4OBgcnNzWbVqlcPbHzNmDIsWLQJg+fLlHD582OFtKMfqFhrIHWMSWHrfRXz+i0v4r/F9yT9cyX8vziH1iRXc++Y6Ptt8gOraeleH6vU87orQVbp27cqYMWMYNGgQHTp0oEePHg3bJkyYwNy5cxkwYAD9+/dn1KhRDm//0Ucf5Uc/+hGvv/46o0ePJjIyktBQ/e7JU/Tu1pEHr+jHA5f3ZX1eKUvXF/BBzj4++m4fnYP9mTi4J5NTohkeF653sriATp/xEFVVVfj6+uLn58fKlSu55557yM7OPq/31N+ra9XU1fPNthKWrC9g+eb9HK+pJyb85CDLBd31HzpHahd3lni7vXv3MnXqVOrr6wkICODll192dUjqPPn7+nBpYncuTezOsapalm/az5L1Bbz4xQ6ez9hBUpQ1yHLdUB1kcTa9IvRi+nt1T0VHj/PBhn0szS4gJ/8IPgIX9olgUnIUE3SQ5ZzpFaFSHqR7aBB3XpTAnRclsKP4GEvXF/BediG/WpzDw+9t5PKBPZiSHM3Yft30ThYHaVUiPM8qdrcDD9u7PmGM+YeDYleq3evTrSMPXtmfB67ox7q9pSy1a7J8lLOP0CA/kmM7kxLbmeS4ziTHhtMlJMDVIXukMyZCu4rd8zSqYici7zdZXHU9kNqoit2fgGki0gV4FGv5fgOstY/VuR9KnQURYXivcIb3Cuc31w7k623FfLb5AOv3lvK3jO2cuKMvrkswybGdSbbrtyRFhRHkr4vMnomzq9hdBXxmjDlkH/sZMAF46/xDV8o7+fv6MD6xB+MTrSlc5VW1fFdwhOy8UjbklZK5+xDvbyi09xUG9AxrSI7JsZ2J7xqiU3SacHYVu+aOjW56QHss3tSxY0eOHTtGYWEhs2fPblhUobFx48bx9NNPk5ra7Pe3ADz77LPMmjWL4OBgwFrWa8GCBXTu3NlZoSsPExLox6jeXRnV++QtnQfKjrN+bynZeaVk5x3mX2vz+efKPQCEBfkxtFGXemhMZ7p2DDzd23uFtqhid0bGmHnAPLBGjR0Zk6tFRUU1mwRb69lnn+XWW29tSITLli1zVGiqHesRFsSEQZFMGBQJQF29YXvRMbLzDpOdV9psl3poo6tGb+tStyYRFgCxjZ7H2K+dwq5i92usKnZVjY4d1+TYL84lUFebM2cOsbGx3HvvvQA89thj+Pn5kZGRweHDh6mpqeGJJ55g0qRJpxzXeB3DyspK7rjjDjZs2EBiYuIp9xrfc889ZGZmUllZyY033sjjjz/Oc889R2FhIZdeeikRERFkZGQQHx9PVlYWERERPPPMM8yfPx+AmTNncv/997N7926uvvpqLrroIr799luio6NZunQpHTpo2Upv5usj9I8MpX9kKNPSrF5XeVUtG+0udXZeKVm7D/FBky710Bg7OcZ1JqEdd6lbkwgzgb4ikoCV2G4Gbmm8g13F7iWsKnaNS3l+CvzermYHcCXw0HlF/PEc2P/deb3FD0QOhqufanGXadOmcf/99zckwkWLFvHpp58ye/ZswsLCKCkpYdSoUaSnp592GfwXX3yR4OBgtmzZQk5ODsOGDWvY9uSTT9KlSxfq6uq47LLLyMnJYfbs2TzzzDNkZGQQERFxynutXbuWv//976xevRpjDCNHjuSSSy4hPDy81ct9Ke8WEujHyN5dGXmaLvWGvFLeXZfP66vaf5f6jInQGFMrIvdhJbUTVew2Na5iB/wZ6Ai8YyeBvcaYdGPMIRH5HVYyBfjtiYETT5OSkkJRURGFhYUUFxcTHh5OZGQkDzzwAF999RU+Pj4UFBRw4MABIiMjm32Pr776itmzZwMwZMgQhgwZ0rBt0aJFzJs3j9raWvbt28fmzZtP2d7UN998w5QpUxpWwbn++uv5+uuvSU9Pb/VyX0o1daYudXbekVO61LFdOpAcG+7xXepWfUdojFkGLGvy2iONHl/ewrHzgfnnGuAPnOHKzZluuukmFi9ezP79+5k2bRpvvvkmxcXFrF27Fn9/f+Lj48+p9vKuXbt4+umnyczMJDw8nBkzZpxXDefWLvel1Jk016WuqK7lu/zmu9R+Pk1GqT2kS613lpyFadOmcdddd1FSUsKXX37JokWL6N69O/7+/mRkZLBnz54Wjx87diwLFixg/PjxbNy4kZycHADKysoICQmhU6dOHDhwgI8//phx48YBJ5f/ato1vvjii5kxYwZz5szBGMOSJUt4/fXXnXLeSjUWHNB8l/pEYsze23yXuvEUHnfrUmsiPAtJSUkcPXqU6OhoevbsyfTp07nuuusYPHgwqampJCYmtnj8Pffcwx133MGAAQMYMGAAw4cPB2Do0KGkpKSQmJhIbGwsY8aMaThm1qxZTJgwgaioKDIyTk7XHDZsGDNmzGDEiBGANViSkpKi3WDlEj3CgrgqKZKrkk7tUm/IK2W9nSCfd+MutS664MX096raUtMu9Ya8UgqPWF8BtUWXWhddUEq5XHNd6qKy4w1XjK7sUmsiVEq5TPdmutQ7io+RvbflLvXQmE6M7deNfg6qEKiJUCnlNnx9hH49QunXI5SpadZ9HBXVtWwsKGuYwrPWHqX+r8oafnFlf4e06zGJ0Bhz2onK6uy523fDSp1OcIAfIxK6MCKhS8NrRWXHwYHpwCNWdQwKCuLgwYP6x+sgxhgOHjxIUJAu/648U/ewILqHOu7z6xFXhDExMeTn51NcXOzqUNqNoKAgYmJiXB2GUm7BIxKhv78/CQkJrg5DKdVOeUTXWCmlnEkToVLK62kiVEp5Pbe7xU5EioGWVy/4oQigxAnhaPvu3ba3t+/N534u7fcyxnRrboPbJcJzISJZp7uHUNtvv217e/vefO6Obl+7xkopr6eJUCnl9dpLIpyn7Xtl297evjefu0PbbxffESql1PloL1eESil1zjwqEYrIBBH5XkS2i8icZrYHishCe/tqEYlv4/ZniEixiGTbPzMd2PZ8ESkSkY2n2S4i8pwdW46IDGtuPye1PU5EjjQ670ea2+882o8VkQwR2Swim0Tk583s45Tzb2XbTjt/EQkSkTUissFu//Fm9nHa576V7Tvtc2+/v6+IrBeRD5vZ5phzN8Z4xA9WKdEdQG8gANgADGyyz8+Aufbjm4GFbdz+DOBvTjr/scAwYONptl8DfIy1ONEoYHUbtj0O+NCJ/+97AsPsx6HA1mZ+9045/1a27bTzt8+no/3YH1gNjGqyjzM/961p32mfe/v9HwQWNPc7dtS5e9IV4QhguzFmpzGmGngbmNRkn0nAP+zHi4HLxHGLGLamfacxxnwFtFQTehLwT2NZBXQWkZ5t1LZTGWP2GWPW2Y+PAluA6Ca7OeX8W9m209jnc8x+6m//NP1i32mf+1a27zQiEgNMBF45zS4OOXdPSoTRQF6j5/n88APZsI8xphY4AnTFMVrTPsANdtdssYjEOqjt1mhtfM4y2u4+fSwiSc5qxO76pGBdmTTm9PNvoW1w4vnbXcNsoAj4zBhz2nN3wue+Ne2D8z73zwL/DdSfZrtDzt2TEqEn+ACIN8YMAT7j5L9U7d06rNuXhgJ/Bd5zRiMi0hH4F3C/MabMGW2cY9tOPX9jTJ0xJhmIAUaIyCBHvr8D2nfK515ErgWKjDFrHfF+LfGkRFgANP6XJsZ+rdl9RMQP6AQcbKv2jTEHjTFV9tNXgOEOars1WvP7cQpjTNmJ7pMxZhngLyIRZzjsrIiIP1YietMY824zuzjt/M/Udlucv/3epUAGMKHJJmd+7s/YvhM/92OAdBHZjfVV1HgReaPJPg45d09KhJlAXxFJEJEArC9G32+yz/vA7fbjG4HPjf0talu03+Q7qXSs75PayvvAbfbo6SjgiDFmX1s0LCKRJ76XEZERWJ8rh/0h2u/9KrDFGPPMaXZzyvm3pm1nnr+IdBORzvbjDsAVQG6T3Zz2uW9N+8763BtjHjLGxBhj4rH+3j43xtzaZDfHnLuzRnqc8YM1MrgVa/T21/ZrvwXS7cdBwDvAdmAN0LuN2/8DsAlrRDkDSHRg228B+4AarO+/7gTuBu62twvwvB3bd0BqG7Z9X6PzXgVc6ODf+0VYX9DnANn2zzVtcf6tbNtp5w8MAdbb7W8EHmnLz30r23fa575RHOOwR42dce56Z4lSyut5UtdYKaWcQhOhUsrraSJUSnk9TYRKKa+niVAp5fU0ESqlvJ4mQqWU19NEqJTyev8fgXD7LirPHk4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjoId37R0yVI"
      },
      "source": [
        "It looks like we could have stopped the training earlier as the validation loss did not decrease afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOHn1utQHqHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb60f1e-931d-4033-bd99-91499e1f86bf"
      },
      "source": [
        "# Let's see the accuracy in the test split\n",
        "scores = text_class_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (text_class_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 - 3s - loss: 0.5271 - accuracy: 0.8161 - 3s/epoch - 3ms/step\n",
            "accuracy: 81.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3HtK17c1S_F"
      },
      "source": [
        "### Saving best performing model\n",
        "\n",
        "Now we save the best performing models using the validation loss as a metric. As you already know, lower training error does not mean in some cases better performance in the validation or test split.\n",
        "\n",
        "In the last example we ran the model for 5 epochs, however after the first epoch the validation loss increased. We want to use the model performing the best in the validation set. To do so, we can use a ModelCheckpoint callback as was explained in past tutorials. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzVNbh5a1xsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4879e0a8-9e39-4b58-e468-c449b02f662a"
      },
      "source": [
        "###### We reset the model #######\n",
        "text_class_model = Sequential()\n",
        "text_class_model.add(Embedding(nb_words,\n",
        "                    embedding_dim,\n",
        "                    input_length=maxlen))\n",
        "text_class_model.add(LSTM(lstm_units))\n",
        "text_class_model.add(Dense(1, activation='sigmoid'))\n",
        "text_class_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#################################\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "## Here we define the checkpoint callback. We first give the name it will use \n",
        "## to save the model. We also specify what metric should monitor, in this case\n",
        "## the validation loss (it could be validation accuracy too for example)\n",
        "## save_best_only means that the models will only be save when the monitored \n",
        "## metric improves with respect to the past best one\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5', verbose=1, \n",
        "                             monitor='val_loss', save_best_only=True)  \n",
        "## Now we pass the callback to the fit method\n",
        "history = text_class_model.fit(x_train, y_train, batch_size=128,\n",
        "                               epochs=epochs, callbacks=[checkpoint],          \n",
        "                               validation_split=validation_split)\n",
        "                             \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 8s 39ms/step - loss: 0.5464 - accuracy: 0.6982 - val_loss: 0.3668 - val_accuracy: 0.8374\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.36677, saving model to model-001.h5\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 5s 34ms/step - loss: 0.3045 - accuracy: 0.8746 - val_loss: 0.3802 - val_accuracy: 0.8318\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.36677\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.2359 - accuracy: 0.9072 - val_loss: 0.3858 - val_accuracy: 0.8286\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.36677\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.1814 - accuracy: 0.9294 - val_loss: 0.4745 - val_accuracy: 0.8224\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.36677\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.1429 - accuracy: 0.9465 - val_loss: 0.4762 - val_accuracy: 0.8092\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.36677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrtRFGUF22tf"
      },
      "source": [
        "We now saved the model after every epoch if the validation loss decreased. In this case, as the best epoch is the first one, it only saves the model after the first epoch. Let's load the model now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwHZ54_22vSa"
      },
      "source": [
        "from keras.models import load_model\n",
        "text_class_model = load_model('model-001.h5')  # load model weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KLudp1u3CHY"
      },
      "source": [
        "And now we check if the accuracy is better compared to when we used the model trained for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsuLgHQu2zqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa2e62b-70ea-457f-8a03-4f23025824b6"
      },
      "source": [
        "# Let's see the accuracy in the test split\n",
        "scores = text_class_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (text_class_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 3s - loss: 0.3680 - accuracy: 0.8382\n",
            "accuracy: 83.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ufb6B68hUhl"
      },
      "source": [
        "### Importance of embeddings\n",
        "Now, let's check quickly if using Embeddings provide any benefit. For this experiment, we remove the Embedding layer, meaning we will be inputting the word index, i.e. an integer, to the LSTM. Additionally, we need to vary the shape of the input data as the LSTM needs a third dimension with the number of channels per input (in this case 1, as each word is represented by an integer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1NY5IhRhppg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec572a4-b07b-4f70-e7b8-9d530925368a"
      },
      "source": [
        "# model parameters\n",
        "# Same model as before but without embeddings\n",
        "lstm_units = 128\n",
        "x_train_r = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test_r = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "\n",
        "print('Build model...')\n",
        "text_class_model = Sequential()\n",
        "\n",
        "text_class_model.add(LSTM(lstm_units, input_shape=(maxlen, 1)))\n",
        "\n",
        "text_class_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "text_class_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(text_class_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_38 (LSTM)               (None, 128)               66560     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 66,689\n",
            "Trainable params: 66,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZaz4eYyiBPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaacf6b-fd24-439d-ffd4-c47eb00a640d"
      },
      "source": [
        "epochs = 5\n",
        "validation_split = 0.2\n",
        "\n",
        "history = text_class_model.fit(x_train_r, y_train, batch_size=128,\n",
        "          epochs=epochs, \n",
        "          validation_split=validation_split)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 3s 10ms/step - loss: 0.7036 - accuracy: 0.5130 - val_loss: 0.6980 - val_accuracy: 0.4938\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6887 - accuracy: 0.5374 - val_loss: 0.6826 - val_accuracy: 0.5676\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6847 - accuracy: 0.5545 - val_loss: 0.6832 - val_accuracy: 0.5696\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6841 - accuracy: 0.5535 - val_loss: 0.6809 - val_accuracy: 0.5690\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6837 - accuracy: 0.5506 - val_loss: 0.6853 - val_accuracy: 0.5584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZcRp4nXiN84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800026b2-fe7e-40bb-e23b-4465dc2629b1"
      },
      "source": [
        "scores = text_class_model.evaluate(x_test_r, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (text_class_model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 2s - loss: 0.6901 - accuracy: 0.5391\n",
            "accuracy: 53.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyOqn7yginQg"
      },
      "source": [
        "We see how the accuracy is just slightly better compared to doing a random guess as there are only 2 classes. That is because the integer that encodes the word is chosen arbitrarily and does not encode any property of the words nor any relationship between words. Hence, using learned embeddings results in models with better capacity/accuracy for this kind of tasks.\n",
        "\n",
        "Instead of inputting directly integers to the RNN, we could argue that another way of representing the input words is to input the one-hot representation of the word directly to the RNN instead of using embeddings. This method has two problems. First, the resulting dimensionality would be too large. In this case we are loading the $20000$ most common words in IMDB, so each word would be encoded in a vector of dimensionality $20000$. Secondly, the encoding does not give any notion of similarity between the different words. For these two reasons, embedding the words to a common lower dimensionality space is also better than using one-hot encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EwrgAmcM9na"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "We now will present an example of text generation using an RNN. We will use the Tiny Shakespeare dataset, which contains samples from Shakespeare works.\n",
        "\n",
        "We pose the problem as a classification problem as in the Sentiment classification example. In a text generation setting, given a sequence, we aim to predict the next one. During the training step, the process would be quite similar to the classification task, i.e. given a sequence you predict a label/word/character. However, in the prediction setting, we aim to output a whole sentence, not only a word or character. For that reason we will follow the procedure explained in the image.\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*XvUt5wDQA8D3C0wAuxAvbA.png)\n",
        "The image is taken from [here](https://medium.com/@david.campion/text-generation-using-bidirectional-lstm-and-doc2vec-models-1-3-8979eb65cb3a)\n",
        "\n",
        "As in the text classification section, we encode the raw sentences in the form of a sequence of integers. In this case, however, we have a text with a really wide vocabulary, and we aim to predict the following element of the sequence. In this dataset the number of words is really large, so if we used a word-level model the number of available classes would be quite large if we did not filter the number of possible words. For this example, instead of encoding on a word level, we will do it on a character level, which results in a more limited vocabulary. We aim to predict the next character when inputting a sentence of length $d$. In evaluation mode, i.e. when we are predicting the next character, we then input a seed of $d$ characters as the first input, and afterwards we use the last $d$ characters as input to predict the next character. \n",
        "\n",
        "The advantages of predicting characters instead of words is that character-level models have a limited vocabulary/classes compared to the number of possible words in a text. They are also more flexible (for example, they can generate \"fake\" url links if trained in e.g. wikipedia data). However, word-level models usually present higher performance as it easier for them to keep track of the long-term meaning of the sentence, and also can avoid any spelling mistakes that may happen in character-level models.\n",
        "\n",
        "**References:** Some code snippets taken from [here](https://www.analyticsvidhya.com/blog/2018/03/text-generation-using-python-nlp/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_-da7NsDrJf"
      },
      "source": [
        "We first download the data we use for the example, and then read the file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcR0v2GGNFCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec67245-8af8-40ec-b847-923d69bcbff2"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt\n",
        "## We read all the raw data in the variable data\n",
        "data = open('./tiny-shakespeare.txt', 'r').read()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-04 21:37:47--  https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘tiny-shakespeare.txt’\n",
            "\n",
            "\rtiny-shakespeare.tx   0%[                    ]       0  --.-KB/s               \rtiny-shakespeare.tx 100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-03-04 21:37:47 (162 MB/s) - ‘tiny-shakespeare.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxFUMjE9kP4C"
      },
      "source": [
        "Let's print a subset of the data for visualization purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c8ZSkLKkX6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f545d80-626a-4b5f-cb92-2ad8a996bcec"
      },
      "source": [
        "print(data[:364])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhZmAeuzD0Wt"
      },
      "source": [
        "We see in the raw text that the name of the characters is printed, that there is a blank line between the different character lines, and also that lines are usually not longer than ~80 characters. We hope the network is capable of learning all of this.\n",
        "\n",
        "Now we will structure the data so we can input it into our RNN model. We aim to encode the text using a sequence of integers as we explained in the classification section.  Hence, we form a dictionary with all the different characters appearing in the text (including whitespaces and punctuation) and its corresponding integer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs3tRv_1whDc"
      },
      "source": [
        "characters = sorted(list(set(data)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEfzwgCnwjwo"
      },
      "source": [
        "Now we want to split the text in examples of length `seq_length` where the label is the next character. As we mentioned, we pose the problem as a set of successive classification problems, where we try to predict the next word given an input sentence. To split the text in pairs of (sequence, next word), we use the dictionary `char_to_n` to encode the different elements as integers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gulHCFMJ_tEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a6748b-932a-4797-ce78-bd8910d1526f"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "length = len(data)\n",
        "seq_length = 100\n",
        "for i in range(0, length-seq_length, 1):\n",
        "  sequence = data[i:i + seq_length]\n",
        "  label = data[i + seq_length]\n",
        "  x.append([char_to_n[char] for char in sequence])\n",
        "  y.append(char_to_n[label])\n",
        "n_samples = len(x)\n",
        "print(\"Total Samples: {:d}\".format(n_samples))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Samples: 1115294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehank2xQFGOo"
      },
      "source": [
        "We now form a test split by using 5% of the available data. To do so, we just take the last 5% of the data. Usually, you need to randomize the data before splitting in test/train to avoid having a different distribution of the data in both splits. However, as this is a sequential data where we want to predict the next character, if we shuffle the splits we would have this in training:\n",
        "\n",
        "``\n",
        "x = 'the boy is tal_' y = 'l'\n",
        "``\n",
        "\n",
        "and this in testing:\n",
        "\n",
        "``\n",
        "x = 'the boy is ta_' y = 'l'\n",
        "``\n",
        "\n",
        "which would contaminate the splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbBqXbtpfa5T"
      },
      "source": [
        "import keras\n",
        "x_train = x[:int(n_samples*0.95)]\n",
        "x_test = x[int(n_samples*0.95):]\n",
        "y_train = y[:int(n_samples*0.95)]\n",
        "y_test = y[int(n_samples*0.95):]\n",
        "\n",
        "## Transform the list to a numpy array\n",
        "x_train = np.reshape(x_train, (len(x_train), seq_length))\n",
        "## Onehot encoding of labels\n",
        "y_train = tf.keras.utils.to_categorical(np.asarray(y_train))\n",
        "\n",
        "x_test = np.reshape(x_test, (len(x_test), seq_length))\n",
        "y_test = tf.keras.utils.to_categorical(np.asarray(y_test))\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U63V-XoLkzD2"
      },
      "source": [
        "Let's print a sequence and the shape of the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_KvSAVQzOvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05285a1-ac3a-4a8d-ec48-fa4365e8da25"
      },
      "source": [
        "print(x_train[8000])\n",
        "print(y_train.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0 13  1 57 47 41 49  1 51 39 52  5 57  1 39 54 54 43 58 47 58 43  6  1\n",
            " 61 46 53  1 42 43 57 47 56 43 57  1 51 53 57 58  1 58 46 39 58  0 35 46\n",
            " 47 41 46  1 61 53 59 50 42  1 47 52 41 56 43 39 57 43  1 46 47 57  1 43\n",
            " 60 47 50  8  1 20 43  1 58 46 39 58  1 42 43 54 43 52 42 57  0 33 54 53\n",
            " 52  1 63 53]\n",
            "(1059529, 65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uudj2qT_FNJG"
      },
      "source": [
        "Here, we define the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13TcalgkqHsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20dcb1f0-2d46-4d80-8d55-f57110d7d80e"
      },
      "source": [
        "# define the LSTM model\n",
        "embedding_size = 100\n",
        "lstm_units = 128\n",
        "\n",
        "text_gen_model = Sequential()\n",
        "text_gen_model.add(Embedding(y_train.shape[1],\n",
        "                    embedding_size, input_length=seq_length))\n",
        "text_gen_model.add(LSTM(lstm_units))\n",
        "text_gen_model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "text_gen_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "text_gen_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          6500      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 65)                8385      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,133\n",
            "Trainable params: 132,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC2BaDcumZnm"
      },
      "source": [
        "The model is a little bit complex, so training takes some time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2EPi_Fee4dj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624ad28a-ed32-4547-daa8-dde3b9790f62"
      },
      "source": [
        "text_gen_model.fit(x_train, y_train, epochs=10 , batch_size=128)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8278/8278 [==============================] - 88s 10ms/step - loss: 1.9989\n",
            "Epoch 2/10\n",
            "8278/8278 [==============================] - 80s 10ms/step - loss: 1.6794\n",
            "Epoch 3/10\n",
            "8278/8278 [==============================] - 79s 9ms/step - loss: 1.5891\n",
            "Epoch 4/10\n",
            "8278/8278 [==============================] - 77s 9ms/step - loss: 1.5395\n",
            "Epoch 5/10\n",
            "8278/8278 [==============================] - 78s 9ms/step - loss: 1.5060\n",
            "Epoch 6/10\n",
            "8278/8278 [==============================] - 78s 9ms/step - loss: 1.4822\n",
            "Epoch 7/10\n",
            "8278/8278 [==============================] - 80s 10ms/step - loss: 1.4640\n",
            "Epoch 8/10\n",
            "8278/8278 [==============================] - 80s 10ms/step - loss: 1.4499\n",
            "Epoch 9/10\n",
            "8278/8278 [==============================] - 81s 10ms/step - loss: 1.4381\n",
            "Epoch 10/10\n",
            "8278/8278 [==============================] - 79s 10ms/step - loss: 1.4282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7259056eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5XsfQRNr9An"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "We now take any of the sequences from the test split and use it as an initial pattern for our model. Then we enter a loop where given an input sequence, we predict the next character and then form a new input sequence by appending the predicted character and dropping the first character.\n",
        "\n",
        "Whenever we input a sequence, we obtain as output a probability distribution of the possible characters. For example, given the sequence `the cat and the do` the model will output a probability distribution of the next character where probably the character `g` will have a high probability (forming then `the cat and the dog`). However, the character `c` can also be a possibility, as the sentence formed may be `the cat and the doctor`. When deciding what character to predict, a strategy is to just take the character with the maximum probability at all times, but then the variability of the formed text is then smaller. Another option would be to sample following the same probability of distribution as the model outputs. However, this might result in a excessive variability with some sentences not making any sense.\n",
        "\n",
        "This trade-off of variability against more probable sequences is controlled by what it is called the temperature of the sampling process. The temperature controls the smoothing of the probability vector. A temperature close to 0 will result in taking always the safest (i.e. that with the highest probability) as the next element. A temperature close to 1 will decide on the next element following the same distribution of probability as the original output of the model.\n",
        "\n",
        "In a more formal way, being $p_i$ the probability of the element $i$ output by the RNN model and $T$ the temperature, the probability after applying the mentioned smoothing $\\hat{p_i}$ is:\n",
        "\n",
        "$$\n",
        "\\hat{p_i} = \\frac{e^{\\log(p_i)/T}}{\\sum_j e^{\\log(p_j)/T}}\n",
        "$$\n",
        "\n",
        "You can check how a small $T$ is going to make the element with the largest probability be close to 1 after the process.\n",
        "\n",
        "Before starting the text prediction, let's show an example of how the sampling temperature affects the model choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loPFAdDvIsWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b25aa6-461d-4d78-dc89-5117d5d03a7b"
      },
      "source": [
        "def temperature_smoothing(prediction, temperature=1.0):\n",
        "  # This function computes the temperature smoothing function\n",
        "  # we explained\n",
        "  prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "  exp_preds = np.exp(prediction)\n",
        "  prediction = exp_preds / np.sum(exp_preds)\n",
        "  return prediction\n",
        "\n",
        "# We have this vector of probabilities\n",
        "prediction = np.asarray([0.2, 0.3, 0.1, 0.4])\n",
        "## Temperature = 1.0\n",
        "print('Output probabilities with temp.=1')\n",
        "print(temperature_smoothing(prediction, temperature=1))\n",
        "## Temperature = 0.5\n",
        "print('Output probabilities with temp.=0.5')\n",
        "print(temperature_smoothing(prediction, temperature=0.5))\n",
        "## Temperature = 0.25\n",
        "print('Output probabilities with temp.=0.25')\n",
        "print(temperature_smoothing(prediction, temperature=0.25))\n",
        "## Temperature = 0.0\n",
        "print('Output probabilities with temp.=0')\n",
        "print(temperature_smoothing(prediction, temperature=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output probabilities with temp.=1\n",
            "[0.20065194 0.29977201 0.10101691 0.39855913]\n",
            "Output probabilities with temp.=0.5\n",
            "[0.13579339 0.30071527 0.03488383 0.5286075 ]\n",
            "Output probabilities with temp.=0.25\n",
            "[0.04948661 0.23537565 0.00344097 0.71169677]\n",
            "Output probabilities with temp.=0\n",
            "[7.88880627e-31 3.20722891e-13 6.22348202e-61 1.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST0l8UWDJy-t"
      },
      "source": [
        "You can see how a lower temperature makes the small probabilities become smaller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnpdKtGwIjue"
      },
      "source": [
        "Here you can set the temperature and check how the output varies. You will see that for $T\\approx0$ the generated text has low variability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REoPwrqieFLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05752ca-8787-4d34-c970-29b56ae3aa10"
      },
      "source": [
        "import sys\n",
        "# Vary the temperature here\n",
        "temperature = 0.5\n",
        "\n",
        "# We select a random element from the test set as seed\n",
        "start = np.random.randint(0, len(x_test)-1)\n",
        "pattern = x_test[start].tolist()\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([n_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "print(\"\\nPredicted:\")\n",
        "# generate 300 characters\n",
        "for i in range(300):\n",
        "  x = np.reshape(pattern, (1, len(pattern)))\n",
        "  prediction = text_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "  ## We put the constant 0.02 to avoid dividing by zero\n",
        "  ## We sum by 1e-7 to avoid log(0)\n",
        "  prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "  exp_preds = np.exp(prediction)\n",
        "  prediction = exp_preds / np.sum(exp_preds)\n",
        "  ## We applied the smoothing with the temperature\n",
        "  ## Now we predict following the probabilities in the variable prediction\n",
        "  prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "  index = np.argmax(prediction)\n",
        "  result = n_to_char[index]\n",
        "  seq_in = [n_to_char[value] for value in pattern]\n",
        "  ## Print the result\n",
        "  sys.stdout.write(result)\n",
        "  \n",
        "  ## Create the input sequence for the next character by appending the predicted\n",
        "  ## character and dropping the first one to always have constant seq. length\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" nse. Would I had never\n",
            "Married my daughter there! for, coming thence,\n",
            "My son is lost and, in my rate \"\n",
            "\n",
            "Predicted:\n",
            " and straight.\n",
            "\n",
            "ROMEO:\n",
            "What you must me think you some son?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "My lord, the crown to for the country.\n",
            "\n",
            "First Servingman:\n",
            "What shall be so? he whom I melt them with me some\n",
            "To the son of the say as they shall procent,\n",
            "And you mean me with the master to me and play\n",
            "To see thee with thy h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSQs-l7OmNoI"
      },
      "source": [
        "Notice how the network has learnt the structure of the text, to start a new line every few words and to put the name of the characters too. The text itself seems grammatically correct in most cases but it fails to make much sense in most examples. Generating sentences with actual semantic meaning is harder for these type of models compared to generating grammatically correct sentences. Test different temperature settings to see how it affects the generation\n",
        "\n",
        "If you want to know more about text generation, along with some extra generated examples, we refer you to [Andrej Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hY4m63VgiM9"
      },
      "source": [
        "### Quantitative evaluation of the generated text\n",
        "\n",
        "For a quantitative evaluation of the generated text we will use a metric commonly used in image captioning and translation tasks, BLEU. BLEU looks for matches on a word level between the generated text and the reference text. Specifically, BLEU looks for matches in n-grams up to $n=4$, where an n-gram is defined as a contiguous sentence of $n$ items. For example, in the sentence `the sky is blue`, an n-gram of $n=2$ would be `is blue`. BLEU scores range from [0,1].\n",
        "\n",
        "As we mentioned, BLEU is usual in more constrained text generation tasks, such as image captioning. In our text generation task there is a large number of both grammatically and semantically correct possibilities when generating new sentences, and one of the issues for this task is to develop a metric that can properly evaluate the semantic and syntactic quality of the generated text. Human evaluation is quite common when evaluating the quality of generated sentences in these less constrained tasks due to the difficulty of finding proper automatic metrics. However, we hope to see a correlation between the BLEU score and the quality of the generated text. Here we take an input sentence from the test data and generate a sentence. Then, we compare the generated sentence to the real one from the corpus. We do so 20 times and provide the average BLEU score.\n",
        "\n",
        "The used function is integrated in the package `nltk` and it is called using the following syntax `sentence_bleu(reference, candidate).`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtnzNZZGr11D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c740682c-79df-41c5-f374-f5bed61f3954"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import sys\n",
        "import time\n",
        "import string\n",
        "a = time.time()\n",
        "characters = sorted(list(set(data)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "temperature = 0.5\n",
        "bleu_score = 0\n",
        "n_eval = 20\n",
        "seq_char_length = 100\n",
        "for _ in range(n_eval):\n",
        "  start = np.random.randint(0, len(x_test)-seq_char_length-1)\n",
        "  pattern = x_test[start].tolist()\n",
        "  reference = x_test[start+seq_char_length].tolist()\n",
        "  reference = ''.join([n_to_char[value] for value in reference])\n",
        "  # generate characters\n",
        "  output_sent = ''\n",
        "  for n_char in range(seq_char_length):\n",
        "    x = np.reshape(pattern, (1, len(pattern)))\n",
        "    prediction = text_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "    prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "    exp_preds = np.exp(prediction)\n",
        "    prediction = exp_preds / np.sum(exp_preds)\n",
        "    prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "    index = np.argmax(prediction)\n",
        "    result = n_to_char[index]\n",
        "    output_sent += result\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:]\n",
        "  # We filter the reference and candidate words to remove any punctuation\n",
        "  # We also use only lower case words\n",
        "  reference = reference.translate(str.maketrans('', '', string.punctuation)).replace('\\n',' ').lower().split(' ')\n",
        "  # We filter any empty element in the list\n",
        "  reference = list(filter(lambda x: x is not '', reference))\n",
        "  candidate = output_sent.replace('\\n',' ').translate(str.maketrans('', '', string.punctuation)).lower().split(' ')\n",
        "  candidate = list(filter(lambda x: x is not '', candidate))\n",
        "  # We remove the first and the last word for both the reference and candidate\n",
        "  # because they may not be completed words\n",
        "  bleu_score += sentence_bleu(reference[1:-1], candidate[1:-1])\n",
        "print(bleu_score/n_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.3012470740715931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEPP1gUthOI0"
      },
      "source": [
        "# Transformers\n",
        "RNNs are still quite used in several architectures and Natural Language Processing (NLP) tasks. However, during the last 3 years (since the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) was published) a new architecture, the Transformer, has started to outperform RNNs in several text/NLP benchmarks. A Transformer does not use any recurrence, it instead uses attention to focus on specific parts of a sentence. If you want an in-depth explanation of the architecture, you can take a look to the [Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) blog post.\n",
        "\n",
        "Both text classification and text generation tasks have been succesfully tackled by transformers. Transfomers seem to scale better than recurrent neural networks, they can have great results when using large architectures and large datasets, whereas RNNs seem not to benefit as much from using more parameters and training examples. State-of-the-art transformer models can have even billions of parameters and can benefit from training in TBs of text data. \n",
        "\n",
        "We will show examples for both text classification and text generation of models pretrained on large datasets. The aim of the examples is to show you how these large models trained in diverse/large datasets can transfer their knowledge to several tasks (similarly to the transfer learning/finetuning section in the CNN Architectures notebook). However, we will not implement any transformer model from scratch. If you are interested in doing so, besides the theoretical explanation of the [Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) blog post, you can also check the [transformers example](https://keras.io/examples/nlp/text_classification_with_transformer/) in the Keras docs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPNbRN4lCkkL"
      },
      "source": [
        "##Text Classification\n",
        "\n",
        "For the text classification task, the model called BERT from Google, and all the subsequent variants have achieved state-of-the-art results. BERT is a method to train language representations, meaning that you then can use those represenations/embeddings to predict the label of the sentence in a text classification task.\n",
        "\n",
        "We will now show a quick example of finetuning BERT in IMDB to show you the capabilities of this model. We take part of the code from [this link](https://colab.research.google.com/drive/18SVeIFXWCiA9HL4WVCAFxlfH59ez6atc#scrollTo=IhHGCuPhv5Ew). To run the following piece of code you may need to restart your environment due to some dependencies issues (it will tell you to do so)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDbm3oUxB7Ly"
      },
      "source": [
        "# install ktrain\n",
        "!pip install ktrain==0.26.3\n",
        "# import ktrain\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "objbxd0QCAnR",
        "outputId": "aa4685a1-8666-4802-8524-c1c24bd9f685"
      },
      "source": [
        "# download IMDb movie review dataset\n",
        "# As we take the code from another notebook, the way to load the\n",
        "# data is different, but the splits are the same as when using imbd.load_data\n",
        "import tensorflow as tf\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")\n",
        "# set path to dataset\n",
        "import os.path\n",
        "#dataset = '/root/.keras/datasets/aclImdb'\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "print(IMDB_DATADIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 1s 0us/step\n",
            "/root/.keras/datasets/aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm4kamkbCFIE"
      },
      "source": [
        "trn, test, preproc = text.texts_from_folder(IMDB_DATADIR, \n",
        "                                          maxlen=500, \n",
        "                                          preprocess_mode='bert',\n",
        "                                          train_test_names=['train', \n",
        "                                                            'test'],\n",
        "                                          classes=['pos', 'neg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83bECt0r36jW"
      },
      "source": [
        "The code below will load a pretrained BERT model and it will start finetuning it in IMDB. We also provide a model finetuned for IMDB as training for 1 epoch takes 1 hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuCksFRVCHQA",
        "outputId": "47e16f6d-8fe9-44a9-d346-c45f4f0dc41a"
      },
      "source": [
        "model = text.text_classifier('bert', trn, preproc=preproc)\n",
        "learner = ktrain.get_learner(model,train_data=trn, val_data=test, batch_size=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgBlcgve4I3t"
      },
      "source": [
        "We train for one epoch (you can skip this step as we already provide a trained model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4mcTiBLCMtl",
        "outputId": "af8ca658-32a4-4388-8826-221124b129a3"
      },
      "source": [
        "learner.fit_onecycle(2e-5, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "4167/4167 [==============================] - 5547s 1s/step - loss: 0.1335 - accuracy: 0.9528 - val_loss: 0.1641 - val_accuracy: 0.9405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa73a97b390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aemVsYcj6swJ"
      },
      "source": [
        "As mentioned, we provide a model already trained. We first download it, load it and test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koan7lanDB9L"
      },
      "source": [
        "!wget https://imperialcollegelondon.box.com/shared/static/w4n0r0l8tm2txvvisq64ysgrgvuwrd4h.zip -O bert.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Rk9MN4DrZU",
        "outputId": "da9993fb-688a-4b53-873c-bc5e1e5f1f3a"
      },
      "source": [
        "!unzip /content/bert.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/bert.zip\n",
            "   creating: bert/\n",
            "  inflating: bert/tf_model.preproc   \n",
            "  inflating: bert/tf_model.h5        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wHbNXzL3V68"
      },
      "source": [
        "# reload Predictor and extract model\n",
        "model = ktrain.load_predictor('/content/bert').model\n",
        "\n",
        "# re-instantiate Learner\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjejlAca4MOl"
      },
      "source": [
        "We evaluate now the performance of the loaded model. The model is quite big, so this evaluation step also takes a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "pNOAf77VhsnB",
        "outputId": "a88a1e2e-1ee0-4762-aa82-61b92d38a7c8"
      },
      "source": [
        "learner.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-33b23d2ae399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, test_data, print_report, save_path, class_names)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, val_data, print_report, save_path, class_names)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel confusion matrices not yet supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, val_data)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yfZcSi56QIl"
      },
      "source": [
        "The accuracy in the IMDB test set is 94% after finetuning for one epoch, which shows the transferability of the knowledge learned with a large transformer in a large dataset. State-of-the-art results have been achieved in several tasks by transferring the knowledge of BERT and similar models to other NLP dataset/task. Even when using only the resources available via Colab we can get state-of-art results in IMDB with a quick finetuning step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPToW5bT5LG6"
      },
      "source": [
        "Let's now predict scores for an example review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKNST0CU0D4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01425cd-af22-496d-b6b3-7dc20d8af075"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model,preproc)\n",
        "predictor.predict_proba('Even though the acting was not superb, the photography was great and the script deserves praise.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02212544, 0.9778746 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flANhpoe5c_W"
      },
      "source": [
        "We can also use the following built-in functionality that allows us to see what words affected the score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "483ugzLxb_2K"
      },
      "source": [
        "# To run \"explain\" you need the following version of the package eli5\n",
        "!pip install git+https://github.com/amaiya/eli5@tfkeras_0_10_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DtXqEoV0Zdj"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model,preproc)\n",
        "predictor.explain('Even though the acting was not superb, the photography was great and the script deserves praise.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CfPJQK7j3JO"
      },
      "source": [
        "## Text Generation\n",
        "\n",
        "In text generation, the GPT variants from OpenAI have shown impressive results. We will now show an example from a pretrained [GPT2](https://openai.com/blog/better-language-models/) using the [Hugging Face](https://huggingface.co/transformers/index.html#) library, which it contains several state-of-the-art Natural Language Processing (NLP) models. The code to generate text is extracted from this [Colab Notebook](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb#scrollTo=HBtDOdD0wx3l).\n",
        "\n",
        "First, we install the Hugging Face library and load a GPT2 pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-nL-6fVRSZ"
      },
      "source": [
        "!pip install ktrain==0.26.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj4IgSwrZ58G"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbs0t7nmkKgi"
      },
      "source": [
        "Now, we generate text using as input a part of the Tiny Shakespeare dataset. Note that this model has not been finetuned using the Tiny Shakespeare dataset, instead it has been trained in a larger more diverse dataset. You can run the following code to get different outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzzXQEW0Z9LO"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode('First Citizen:\\nBefore we proceed any further, hear me speak.\\nAll:\\nSpeak, speak.\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?', return_tensors='tf')\n",
        "\n",
        "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=200, \n",
        "    top_k=50\n",
        ")\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBWzhH76cZTr"
      },
      "source": [
        "What is quite impressive about the output of the GPT model is the capability of matching the style of the input text. The model is not finetuned in our dataset, but it still generates characters names and similary grammar/vocabulary to the given input. This is the result of the large capacity of the model and the diverse training data it used.\n",
        "\n",
        "Let's try to change the input to a completely different one, using in this case an input from a rugby game."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RN1CBKGdN8W"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode(\"40 mins. Tom Curry receives Stuart Hogg’s kick-off and Youngs kicks poorly to put Scotland back on the attack.\\n\", return_tensors='tf')\n",
        "\n",
        "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=100, \n",
        "    top_k=50\n",
        ")\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z956_MZLetBY"
      },
      "source": [
        "We see how the model understands that the input is related to sports and changes the output style compared to the Tiny Shakespeare example.\n",
        "\n",
        "We just showed examples with GPT2. However, the newer version of GPT, GPT3, which is trained using a quite larger model and dataset, shows largely improved results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwawQJMZ3aQM"
      },
      "source": [
        "# Coursework\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKfTmNC7Bj5E"
      },
      "source": [
        "### **Task 1: RNN Regression**\n",
        "\n",
        "In this task, you are asked to estimate the next value of a time series. Specifically, we have selected the popular airline passenger dataset. This dataset contains the number of passengers that travels with a certain airline company. The data contains 144 entries, each entry corresponds to the number of the passengers that travel in a given month. The dataset starts in 1949, and it lasts until 1960. \n",
        "\n",
        "Similarly to the previous example, we import the data and plot it to see the structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRf3UGQ33bnN"
      },
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
        "data = pandas.read_csv('airline-passengers.csv', usecols=[1], engine='python')\n",
        "plt.plot(data)\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.title(\"Airline Passengers from January 1949 to December 1960 (12 years)\")\n",
        "plt.show()\n",
        "\n",
        "# convert pandas data frame in numpy array of float.\n",
        "data_np = data.values.astype(\"float32\")\n",
        "\n",
        "# normalize data with min max normalization\n",
        "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
        "dataset = normalizer.fit_transform(data_np)\n",
        "\n",
        "# Using 70% of data for training, 30% for test.\n",
        "TRAINING_PERC = 0.70\n",
        "\n",
        "train_size = int(len(dataset) * TRAINING_PERC)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
        "print(\"Number of samples training set: \" + str((len(train))))\n",
        "print(\"Number of samples test set: \" + str((len(test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOi9udyY3dHS"
      },
      "source": [
        "First of all, you need to train an RNN on the airline passenger dataset. This exercise expects you to study the impact of the `window_size` variable when defining the `train` and `test` dataset splits. Remember that the `window_size` variable indicates the number of past observations used for predicting the current value. Here, we treat the `test` split as a validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIB08JxD3ezu"
      },
      "source": [
        "def create_dataset(dataset, window_size = 1):\n",
        "    data_x, data_y = [], []\n",
        "    for i in range(len(dataset) - window_size - 1):\n",
        "        sample = dataset[i:(i + window_size), 0]\n",
        "        data_x.append(sample)\n",
        "        data_y.append(dataset[i + window_size, 0])\n",
        "    return(np.array(data_x), np.array(data_y))\n",
        "\n",
        "window_size = 1 #Use this variable to build the dataset with different number of inputs\n",
        "\n",
        "# Create test and training sets for regression with different window sizes.\n",
        "train_X, train_Y = create_dataset(train, window_size)\n",
        "test_X, test_Y = create_dataset(test, window_size)\n",
        "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
        "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
        "\n",
        "print(\"Shape of training inputs: \" + str((train_X.shape)))\n",
        "print(\"Shape of training labels: \" + str((train_Y.shape)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH6W6t5q3gfN"
      },
      "source": [
        "\n",
        "**Report**:\n",
        "\n",
        "*   Create a plot showing the test curves of models trained with different `window_size` values. Report the plot and discuss the main differences you observe between the predicted curves. You can use the style proposed on the Many to One RNNs - Regression section to plot your curves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwb9IfiCLKuT"
      },
      "source": [
        "### **Task 2: Text Embeddings**\n",
        "For this task, we tackle a classification problem using the IMDB sentiment dataset as done in the example in the notebook. Labels in IMDB are 0 for negative reviews and 1 for positive reviews. The definitions of the models you will use for this task are given the code below. This task is similar to the transfer learning/finetuning task in the CNN Architectures notebook, however we now test the effect of transfer learning in the embeddings. In this task we use train, validation and test splits with Early Stopping. That means that we will take the best performing model in the validation set and use it in the test set to get a final performance.\n",
        "\n",
        "**Report**\n",
        "* Using embeddings of dimensionality 1, train a model without using any LSTM, only using an average pooling of the input embeddings (called `embeddings_model` in the code given below). Then train another model with an LSTM and trainable embeddings initialized at random (called `lstm_model`). Finally train a model with an LSTM with non-trainable embeddings initialized with GloVe embeddings (called `lstm_glove_model`). The code to train the three models is given below. Report in a table the test accuracy obtained after training with the given code for the three models. Also attach in the Appendix the training and validation accuracy curves for the different models trained. You can report the curves after using EarlyStopping with patience 10 (already given in the code), so you don't have to train for the full 50 epochs the three models. Discuss the results.\n",
        "\n",
        "* Predict the sentiment of the two given example reviews in the code below for the model trained without a LSTM (`embeddings_model`) and for the model trained with a LSTM and GloVe embeddings (`lstm_glove_model`). Report the predictions (you can use the same table as when reporting test accuracies). Discuss the results. Also discuss the differences you can observe between the GloVe embeddings and the embeddings learnt in `embeddings_model` (e.g. what kind of properties the embeddings encode, or differences in the closest words).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gq0lcyLnaSN"
      },
      "source": [
        "We provide the training code you need to use for this exercise below. First we load the dataset as we did in the tutorial. In this exercise, we will use of train, validation and test splits, which are defined in the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ibhzVdnZ0X"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout, Flatten\n",
        "from keras.layers import LSTM, GlobalAvgPool1D\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# number of most-frequent words to use\n",
        "nb_words = 5000\n",
        "n_classes = 1\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=nb_words)\n",
        "print('x_train:', x_train.shape)\n",
        "print('x_test:', x_test.shape)\n",
        "# get_word_index retrieves a mapping word -> index\n",
        "word_index = imdb.get_word_index()\n",
        "# We make space for the three special tokens\n",
        "word_index_c = dict((w, i+3) for (w, i) in word_index.items())\n",
        "word_index_c['<PAD>'] = 0\n",
        "word_index_c['<START>'] = 1\n",
        "word_index_c['<UNK>'] = 2\n",
        "# Instead of having dictionary word -> index we form\n",
        "# the dictionary index -> word\n",
        "index_word = dict((i, w) for (w, i) in word_index_c.items())\n",
        "# Truncate sentences after this number of words\n",
        "maxlen = 100\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "x_val = x_train[23000:]\n",
        "y_val = y_train[23000:]\n",
        "x_train = x_train[:23000]\n",
        "y_train = y_train[:23000]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EDi21HPGU3h"
      },
      "source": [
        "The following code includes the model that uses embeddings of size 1 (so each word is only represented by a single digit) and averages them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7421cnIYoPQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d6cf6b-2178-4b59-a2ae-fd586cd76da4"
      },
      "source": [
        "# Dimensions of the embeddings\n",
        "embedding_dim = 1\n",
        "\n",
        "print('Build model...')\n",
        "embeddings_model = Sequential()\n",
        "\n",
        "embeddings_model.add(Embedding(nb_words,\n",
        "                    embedding_dim,\n",
        "                    input_length=maxlen,\n",
        "                            trainable=True))\n",
        "embeddings_model.add(GlobalAvgPool1D())\n",
        "embeddings_model.add(Dense(1, activation='sigmoid'))\n",
        "embeddings_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(embeddings_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 1)            5000      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 5,002\n",
            "Trainable params: 5,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRm3ql3UE9w7"
      },
      "source": [
        "We use Early Stopping, so the best validation model is then used to compute the result in the test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gom37wigpZAn"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "## We train the model for at most 50 epochs\n",
        "epochs = 50\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = embeddings_model.fit(x_train, y_train, batch_size=32, epochs=epochs, callbacks=[early_stop], validation_data=(x_val,y_val))\n",
        "print('Final test accuracy is:')\n",
        "embeddings_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_DTYhcl68GF"
      },
      "source": [
        "Now we have `embedding_model` trained. The code below will print the embedding of any `query_word`, which in this case is a single number. We also give you the code to compute the `top_k` closest embeddings to `query_word`. The metric used is the L2 distance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9uJoVAt7EWk"
      },
      "source": [
        "weights = embeddings_model.layers[0].get_weights()[0]\n",
        "query_word = '8'\n",
        "dist = ((weights - weights[word_index_c[query_word]])**2).sum(1).argsort()\n",
        "top_k = 10\n",
        "print(\"Embedding value of {:s} is {:f}\", query_word, weights[word_index_c[query_word]][0])\n",
        "print('Most {:d} similar words to {:s}'.format(top_k, query_word))\n",
        "for k in range(1, top_k+1):\n",
        "  print(\"{:d}: {:s}\".format(k, index_word[dist[k]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhD9hosS7cKQ"
      },
      "source": [
        "The code below gives the prediction for two example reviews we input. Remember that predictions close to 0 refer to a negative review, and predictions close to 1 refer to a positive review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqatHlu8glYQ"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "negative_review = \"the movie is boring and not good\"\n",
        "words = negative_review.split()\n",
        "seq_input = [word_index_c[w] for w in words]\n",
        "seq_input = np.array([seq_input])\n",
        "seq_input = pad_sequences(seq_input,maxlen=100)\n",
        "negative_review_score = embeddings_model.predict(seq_input)\n",
        "\n",
        "positive_review = \"the movie is good and not boring\"\n",
        "words = positive_review.split()\n",
        "seq_input = [word_index_c[w] for w in words]\n",
        "seq_input = np.array([seq_input])\n",
        "seq_input = pad_sequences(seq_input,maxlen=100)\n",
        "positive_review_score = embeddings_model.predict(seq_input)\n",
        "\n",
        "print(\"The score for the negative review is:\", negative_review_score)\n",
        "print(\"The score for the positive review is:\", positive_review_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FzItW89aLVj"
      },
      "source": [
        "With the above code, we trained a model that classifies the sentiment of the sentence using the average of all the embeddings, which were only of size 1. Now we will increase the capacity of the embeddings to 300 and will also add a LSTM to process the embeddings. Hence, the model has a much higher capacity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-z4K9iAaKR1"
      },
      "source": [
        "## Model parameters:\n",
        "# Dimensions of the embeddings\n",
        "embedding_dim = 300\n",
        "\n",
        "## LSTM dimensionality\n",
        "lstm_units = 50\n",
        "\n",
        "print('Build model...')\n",
        "lstm_model = Sequential()\n",
        "\n",
        "lstm_model.add(Embedding(nb_words,\n",
        "                    embedding_dim,\n",
        "                    input_length=maxlen,\n",
        "                            trainable=True))\n",
        "### Do not modify the layers below\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(LSTM(lstm_units, dropout=0.2))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "lstm_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(lstm_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msBDHkgfFhtq"
      },
      "source": [
        "Similarly, we use EarlyStopping for this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXpHfGa-aoWW"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "## We train the model for 50 epochs\n",
        "epochs = 50\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = lstm_model.fit(x_train, y_train, batch_size=32, epochs=epochs, callbacks=[early_stop], validation_data=(x_val,y_val))\n",
        "print('Final test accuracy is:')\n",
        "lstm_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3F0IRz2FqVX"
      },
      "source": [
        "We just trained a model with a large number of parameters in the IMDB, which is a small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7dnHR3za1xB"
      },
      "source": [
        "The last model we train is the same model as the `lstm_model` above, but in this case we use the embeddings from the GloVe method (which were introduced in this notebook) without any finetuning. First, we download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7ZjGnuWb4H9"
      },
      "source": [
        "!wget https://imperialcollegelondon.box.com/shared/static/c9trfhhwl9ohje5g3sapu3xk2zoywp3c.txt -O gensim_glove_vectors.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vhK-7g7GIZX"
      },
      "source": [
        "Then we load the GloVe embeddings with dimensionality 300 we just downloaded. This takes some time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KeP7idDb-Wj"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV_QslV7ctj4"
      },
      "source": [
        "We now load the pretrained embeddings in a numpy array to then pass it to the Keras Embedding layer. Change the shape of `embedding_matrix` to the corresponding embedding dimensionality you are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBJO9pOcA9D"
      },
      "source": [
        "import numpy as np\n",
        "embedding_matrix = np.zeros((nb_words, 300))\n",
        "for word, i in word_index_c.items():\n",
        "    if word in glove_model:\n",
        "      embedding_vector = glove_model[word]\n",
        "      if embedding_vector is not None and i < nb_words:\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEgmD5CdbEo"
      },
      "source": [
        "To initialize the Keras Embedding layer with the embeddings we loaded, we can use the argument `weights=[embedding_matrix]`. Also, to freeze the embeddings during training, we use `trainable=False`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTDZJhNqbFiz"
      },
      "source": [
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers import GlobalMaxPool1D, Flatten, GlobalAvgPool1D, Dropout\n",
        "\n",
        "## Model parameters:\n",
        "# Dimensions of the embeddings\n",
        "embedding_dim = 300\n",
        "\n",
        "## LSTM dimensionality\n",
        "lstm_units = 50\n",
        "\n",
        "print('Build model...')\n",
        "lstm_glove_model = Sequential()\n",
        "\n",
        "lstm_glove_model.add(Embedding(nb_words,\n",
        "                    embedding_dim,\n",
        "                    input_length=maxlen,\n",
        "                    weights=[embedding_matrix],\n",
        "                            trainable=False))\n",
        "### Do not modify the layers below\n",
        "lstm_glove_model.add(Dropout(0.2))\n",
        "lstm_glove_model.add(LSTM(lstm_units, dropout=0.2))\n",
        "lstm_glove_model.add(Dropout(0.2))\n",
        "lstm_glove_model.add(Dense(1, activation='sigmoid'))\n",
        "lstm_glove_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(lstm_glove_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7c-u98zbJaf"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "## We train the model for 50 epochs\n",
        "epochs = 50\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = lstm_glove_model.fit(x_train, y_train, batch_size=32, epochs=epochs, callbacks=[early_stop], validation_data=(x_val,y_val))\n",
        "print('Final test accuracy is:')\n",
        "lstm_glove_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0v3mUULGkfV"
      },
      "source": [
        "We can also compute the closest words in the GloVe embeddings to any `query_word` using the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQDqhKtOc56X"
      },
      "source": [
        "query_word = '8'\n",
        "weights = embedding_matrix\n",
        "\n",
        "dist = ((weights - weights[word_index_c[query_word]])**2).sum(1).argsort()\n",
        "top_k = 10\n",
        "print('Most {:d} similar words to {:s}'.format(top_k, query_word))\n",
        "for k in range(1, top_k+1):\n",
        "  print(\"{:d}: {:s}\".format(k, index_word[dist[k]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXiBKBgtG2xf"
      },
      "source": [
        "We use the same example reviews as for the `embedding_model` case and we compute the predictions using the `lstm_glove_model`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z10tY2Nyg9px"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "negative_review = \"the movie is boring and not good\"\n",
        "words = negative_review.split()\n",
        "seq_input = [word_index_c[w] for w in words]\n",
        "seq_input = np.array([seq_input])\n",
        "seq_input = pad_sequences(seq_input,maxlen=100)\n",
        "negative_review_score = lstm_glove_model.predict(seq_input)\n",
        "\n",
        "positive_review = \"the movie is good and not boring\"\n",
        "words = positive_review.split()\n",
        "seq_input = [word_index_c[w] for w in words]\n",
        "seq_input = np.array([seq_input])\n",
        "seq_input = pad_sequences(seq_input,maxlen=100)\n",
        "positive_review_score = lstm_glove_model.predict(seq_input)\n",
        "\n",
        "print(negative_review_score, positive_review_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CywiPmy1eZoF"
      },
      "source": [
        "### **Task 3: Text Generation**\n",
        "In this task we focus on the text generation problem. For this purpose, we will download the scripts of the TV show Game of Thrones and try to generate some text resembling the style of the scripts.\n",
        "\n",
        "\n",
        "**Report**\n",
        "* Plot the retrieved BLEU for different temperature values (from 0 to 2 in the x-axis) for both the character-level model and the word-level model. To compute the BLEU score, use a minimum of 20 generated samples per temperature used to reduce variability (you can increase it at the cost of higher computational time for lower variability). Each sample should contain 100 characters for the char-level model or 30 words for the word-level model (the code given uses these parameters by default). Do you see any relationship between the obtained BLEU score and temperature used? If you generate sentences at different temperatures what differences can you observe? Are the generated sentences grammatically correct? Do the generated sentences make sense? \n",
        "\n",
        "We give below the code needed to download the dataset and to compute the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD9gEFKXqukY"
      },
      "source": [
        "We first download and read the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_I1pRickXKl"
      },
      "source": [
        "!git clone https://github.com/shekharkoirala/Game_of_Thrones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1i9e9nekb70"
      },
      "source": [
        "data = open('./Game_of_Thrones/Data/final_data.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHqzKZQ8aYkp"
      },
      "source": [
        "**Character-level model**\n",
        "\n",
        "We first include the code to build the character-level dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnwDgj_unBhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cca5c0-01fc-4119-f0f8-cdd9af987e8e"
      },
      "source": [
        "characters = sorted(list(set(data)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "x_char = []\n",
        "y_char = []\n",
        "length = len(data)\n",
        "seq_char_length = 100\n",
        "for i in range(0, length-seq_char_length):\n",
        "  sequence = data[i:i + seq_char_length]\n",
        "  label = data[i + seq_char_length]\n",
        "  x_char.append([char_to_n[char] for char in sequence])\n",
        "  y_char.append(char_to_n[label])\n",
        "n_samples = len(x_char)\n",
        "print ('Total Samples:' , n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Samples: 2474358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcmI8iV7afK5"
      },
      "source": [
        "The splits used for training are given below, although we already give the model trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkGsFkMnCuB"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "x_train_char = x_char[:int(n_samples*0.8)]\n",
        "x_test_char = x_char[int(n_samples*0.8):]\n",
        "y_train_char = y_char[:int(n_samples*0.8)]\n",
        "y_test_char = y_char[int(n_samples*0.8):]\n",
        "## Transform the list to a numpy array\n",
        "x_train_char = np.reshape(x_train_char, (len(x_train_char), seq_char_length))\n",
        "## Onehot encoding of labels\n",
        "y_train_char = tf.keras.utils.to_categorical(np.asarray(y_train_char))\n",
        "\n",
        "x_test_char = np.reshape(x_test_char, (len(x_test_char), seq_char_length))\n",
        "y_test_char = tf.keras.utils.to_categorical(np.asarray(y_test_char))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcyzP955aukz"
      },
      "source": [
        "The definition of the model is the one given below. You will not train the model, so this piece of code is only for you to know what kind of model we trained for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO3FoRM1nEOe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n",
        "# define the LSTM model\n",
        "embedding_size = 300\n",
        "lstm_units = 256\n",
        "\n",
        "char_gen_model = Sequential()\n",
        "char_gen_model.add(Embedding(y_train_char.shape[1],\n",
        "                    embedding_size, input_length=seq_char_length))\n",
        "char_gen_model.add(LSTM(lstm_units))\n",
        "char_gen_model.add(Dense(y_train_char.shape[1], activation='softmax'))\n",
        "\n",
        "char_gen_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "char_gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSgGhwym_WLx"
      },
      "source": [
        "As the training takes a while, we include a saved model that you can load to skip the training step. Use this model to compute your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcasWx79nFcY"
      },
      "source": [
        "!wget https://imperialcollegelondon.box.com/shared/static/1ffasfm5bx691allukv4y8n0tglr5c06.h5 -O ./char_model.h5\n",
        "char_gen_model = keras.models.load_model(\"./char_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsuUE8vua77e"
      },
      "source": [
        "The code you need to evaluate the BLEU score is given below. Vary the temperature to the different needed values. It takes around 1 minute in average per temperature if `n_eval` is set to 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5ufMSdgp0A6"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import sys\n",
        "import time\n",
        "import string\n",
        "a = time.time()\n",
        "characters = sorted(list(set(data)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "temperature = 1.0\n",
        "bleu_score = 0\n",
        "n_eval = 20\n",
        "seq_char_length = 100\n",
        "for _ in range(n_eval):\n",
        "  start = np.random.randint(0, len(x_test_char)-seq_char_length-1)\n",
        "  pattern = x_test_char[start].tolist()\n",
        "  reference = x_test_char[start+seq_char_length].tolist()\n",
        "  reference = ''.join([n_to_char[value] for value in reference])\n",
        "  # generate characters\n",
        "  output_sent = ''\n",
        "  for n_char in range(seq_char_length):\n",
        "    x = np.reshape(pattern, (1, len(pattern)))\n",
        "    prediction = char_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "    prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "    exp_preds = np.exp(prediction)\n",
        "    prediction = exp_preds / np.sum(exp_preds)\n",
        "    prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "    index = np.argmax(prediction)\n",
        "    result = n_to_char[index]\n",
        "    output_sent += result\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:]\n",
        "  # We filter the reference and candidate words to remove any punctuation\n",
        "  # We also use only lower case words\n",
        "  reference = reference.translate(str.maketrans('', '', string.punctuation)).replace('\\n',' ').lower().split(' ')\n",
        "  # We filter any empty element in the list\n",
        "  reference = list(filter(lambda x: x is not '', reference))\n",
        "  candidate = output_sent.replace('\\n',' ').translate(str.maketrans('', '', string.punctuation)).lower().split(' ')\n",
        "  candidate = list(filter(lambda x: x is not '', candidate))\n",
        "  # We remove the first and the last word for both the reference and candidate\n",
        "  # because they may not be completed words\n",
        "  bleu_score += sentence_bleu(reference[1:-1], candidate[1:-1])\n",
        "print(bleu_score/n_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVEF_WPycOnD"
      },
      "source": [
        "The code below allows you to generate sentences for different input patterns and different temperature values. You can test how the temperature values affect the quality of the output sentences for the character-level model by generating a few examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yshz7OZGnIWX"
      },
      "source": [
        "import sys\n",
        "# Change the temperature here\n",
        "temperature = 0.5\n",
        "# You can modify the input pattern here.\n",
        "pattern = [char_to_n[value] for value in list(\"TYRION pours himself some wine and drinks it down. He pours another glass, and walks back to CERSEI \")]\n",
        "pattern = pattern[:seq_char_length]\n",
        "print(\"\\nPredicted:\")\n",
        "# generate 300 characters\n",
        "for i in range(300):\n",
        "  x = np.reshape(pattern, (1, len(pattern)))\n",
        "  prediction = char_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "  ## We put the constant 0.02 to avoid dividing by zero\n",
        "  ## We sum by 1e-7 to avoid log(0)\n",
        "  prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "  exp_preds = np.exp(prediction)\n",
        "  prediction = exp_preds / np.sum(exp_preds)\n",
        "  ## We applied the smoothing with the temperature\n",
        "  ## Now we predict following the probabilities in the variable prediction\n",
        "  prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "  index = np.argmax(prediction)\n",
        "  result = n_to_char[index]\n",
        "  seq_in = [n_to_char[value] for value in pattern]\n",
        "  ## Print the result\n",
        "  sys.stdout.write(result)\n",
        "  \n",
        "  ## Create the input sequence for the next character by appending the predicted\n",
        "  ## character and dropping the first one to always have constant seq. length\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeNwJWRN0Mue"
      },
      "source": [
        "**Word-level model**\n",
        "\n",
        "We now give the code to run the word-level model. The code is similar to the char-level model. The main difference is that we only try to predict the 2000 words most commonly used in the dataset. The reason for this limitation is to limit the size of the output layer and number of input embeddings for memory constraints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-XfzutEv9Ta",
        "outputId": "1d8300cc-89e5-482c-d521-2dd6ca540ddc"
      },
      "source": [
        "from collections import Counter\n",
        "n_words = 2000\n",
        "# We preprocess the data to separate the punctuation from the words so e.g.\n",
        "# \"sword.\" and \"sword\" are not treated as separate words. \n",
        "# We also use only lower-cased words\n",
        "data_p = data.replace('.', ' . ').replace(',', ' , ').replace(':', ' : ').replace('?', ' ? ')\n",
        "data_p = data_p.replace('!', ' !').replace('\\n', ' \\n ').replace('[', ' [ ').replace(']', ' ] ')\n",
        "data_p = data_p.replace(')', ' ) ').replace('(', ' ( ').lower().split(' ')\n",
        "data_p = list(filter(lambda x: x is not '' and x is not ' ', data_p))\n",
        "common = dict(Counter(data_p).most_common(n_words))\n",
        "n_to_word = {n:word for n, word in enumerate(common.keys())}\n",
        "word_to_n = {word:n for n, word in enumerate(common.keys())}\n",
        "x_word = []\n",
        "y_word = []\n",
        "length = len(data_p)\n",
        "seq_length = 30\n",
        "for i in range(0, length-seq_length):\n",
        "  sequence = data_p[i:i + seq_length]\n",
        "  label = data_p[i + seq_length]\n",
        "  seq = []\n",
        "  if label in common:\n",
        "    for word in sequence:\n",
        "      if word in word_to_n:\n",
        "        seq.append(word_to_n[word])\n",
        "      else:\n",
        "        # If the word in the input sequence is not from the most common 2000 \n",
        "        # words, we use a special token. We use the same token for all the \n",
        "        # non-common words.\n",
        "        seq.append(len(word_to_n))\n",
        "    x_word.append(seq)\n",
        "    y_word.append(word_to_n[label])\n",
        "n_samples = len(x_word)\n",
        "print('Total Samples:' , n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Samples: 544224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teAOmchqxvQd"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "x_train_word = x_word[:int(n_samples*0.8)]\n",
        "x_test_word = x_word[int(n_samples*0.8):]\n",
        "y_train_word = np.array(y_word[:int(n_samples*0.8)])\n",
        "y_test_word = np.array(y_word[int(n_samples*0.8):])\n",
        "## Transform the list to a numpy array\n",
        "x_train_word = np.reshape(x_train_word, (len(x_train_word), seq_length))\n",
        "\n",
        "x_test_word = np.reshape(x_test_word, (len(x_test_word), seq_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJvV2NaP0yam"
      },
      "source": [
        "The definition of the word-level model we train is given below. The model is the same as in the char-level case, the only difference is the size of the output vector and the number of input embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myJRka3BxyUf"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM\n",
        "# define the LSTM model\n",
        "embedding_size = 300\n",
        "lstm_units = 256\n",
        "\n",
        "word_gen_model = Sequential()\n",
        "word_gen_model.add(Embedding(n_words + 1,\n",
        "                    embedding_size, input_length=seq_length))\n",
        "word_gen_model.add(LSTM(lstm_units))\n",
        "word_gen_model.add(Dense(n_words + 1, activation='softmax'))\n",
        "\n",
        "word_gen_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "word_gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s10IJIxrzEUE"
      },
      "source": [
        "!wget https://imperialcollegelondon.box.com/shared/static/h38nnk3mbi0zl1w6x76uilawivpeklhz.h5 -O ./word_model.h5\n",
        "word_gen_model = keras.models.load_model(\"./word_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgvJiBOs5CEF"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import string\n",
        "import sys\n",
        "temperature = 1.0\n",
        "bleu_score = 0\n",
        "n_eval = 20\n",
        "seq_length = 30\n",
        "for _ in range(n_eval):\n",
        "  # We look for references that do not contain any non-common words as we only\n",
        "  # learnt to predict the 2000 most common words\n",
        "  while True:\n",
        "    start = np.random.randint(0, len(x_test_word)-seq_length-1)\n",
        "    pattern = x_test_word[start].tolist()\n",
        "    reference = x_test_word[start+seq_length].tolist()\n",
        "    if n_words not in reference:\n",
        "      break\n",
        "  reference = ' '.join([n_to_word[value] for value in reference])\n",
        "  # generate words\n",
        "  output_sent = ''\n",
        "  for i in range(seq_length):\n",
        "    x = np.reshape(pattern, (1, len(pattern)))\n",
        "    prediction = word_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "    prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "    exp_preds = np.exp(prediction)\n",
        "    prediction = exp_preds / np.sum(exp_preds)\n",
        "    prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "    index = np.argmax(prediction)\n",
        "    result = n_to_word.get(index, '')\n",
        "    output_sent += result + ' '\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:]\n",
        "  # We filter the reference and candidate words to remove any punctuation\n",
        "  reference = reference.translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ').split(' ')\n",
        "  # We filter any empty element in the list\n",
        "  reference = list(filter(lambda x: x is not '', reference))\n",
        "  candidate = output_sent.replace('\\n',' ').translate(str.maketrans('', '', string.punctuation)).split(' ')\n",
        "  candidate = list(filter(lambda x: x is not '', candidate))\n",
        "  bleu_score += sentence_bleu([reference], candidate)\n",
        "print(bleu_score/n_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1cYUeC27W3"
      },
      "source": [
        "import sys\n",
        "# Vary the temperature here\n",
        "temperature = 1.0\n",
        "pattern = \"TYRION pours himself some wine and drinks it down. He pours another glass, and walks back to CERSEI placing his cup on her desk. He takes another glass.\\nTYRION: \"\n",
        "# Process input pattern\n",
        "pattern = pattern.replace('.', ' . ').replace(',', ' , ').replace(':', ' : ').replace('?', ' ? ')\n",
        "pattern = pattern.replace('!', ' !').replace('\\n', ' \\n ').replace('[', ' [ ').replace(']', ' ] ')\n",
        "pattern = pattern.replace(')', ' ) ').replace('(', ' ( ').lower().split(' ')\n",
        "pattern = list(filter(lambda x: x is not '' and x is not ' ', pattern))\n",
        "\n",
        "pattern = pattern[:seq_length]\n",
        "\n",
        "print(\"\\nInput Pattern:\\n\", ' '.join(pattern))\n",
        "pattern = [word_to_n.get(value, n_words) for value in pattern]\n",
        "print(\"\\nPredicted:\")\n",
        "# generate 100 words\n",
        "for i in range(100):\n",
        "  x = np.reshape(pattern, (1, len(pattern)))\n",
        "  prediction = word_gen_model.predict(x, verbose=0).astype(np.float64)\n",
        "  ## We put the constant 0.02 to avoid dividing by zero\n",
        "  ## We sum by 1e-7 to avoid log(0)\n",
        "  prediction = np.log(prediction + 1e-7) / (temperature + 0.01)\n",
        "  exp_preds = np.exp(prediction)\n",
        "  prediction = exp_preds / np.sum(exp_preds)\n",
        "  ## We applied the smoothing with the temperature\n",
        "  ## Now we predict following the probabilities in the variable prediction\n",
        "  prediction = np.random.multinomial(1, prediction[0,:], 1)\n",
        "  index = np.argmax(prediction)\n",
        "  result = n_to_word[index]\n",
        "  ## Print the result\n",
        "  sys.stdout.write(result+' ')\n",
        "  \n",
        "  ## Create the input sequence for the next character by appending the predicted\n",
        "  ## character and dropping the first one to always have constant seq. length\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}